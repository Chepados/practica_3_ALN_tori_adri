{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vamos a aplicar ahora lso conocimientos adquiridos de la guía básica para desarrollar nuestra versión de la api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data/knowledge_base.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    database = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nYour Brain on Music: Tearjerkers\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to Main Content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n                        <strong data-cart-timer=\"\" role=\"text\"></strong>\\r\\n                    \\n\\n\\n\\n\\n\\nNavigation\\n\\n\\n\\nKennedy Center\\n\\n\\n\\n\\n\\nKennedy Center\\n\\n\\n\\n\\nPage Navigation\\n\\n\\nWhat’s On\\n\\n\\nVisit\\n\\n\\nDigital Stage\\n\\n\\nSupport\\n\\n\\nEducation\\n\\n\\nOur Story\\n\\n\\nMemorial\\n\\n\\nShop\\n\\n\\n\\n\\nPartner Organizations\\n\\n\\nNational Symphony Orchestra\\n\\n\\nWashington National Opera\\n\\n\\n\\n\\nUtility\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNavigation\\n\\n\\n\\n\\nKennedy Center\\n\\n\\n\\n\\n\\n\\n\\nUtility\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle Menu\\n\\n\\n\\nPage Navigation\\n\\n\\nWhat’s On\\n\\n\\nVisit\\n\\n\\nDigital Stage\\n\\n\\nSupport\\n\\n\\nEducation\\n\\n\\nOur Story\\n\\n\\nMemorial\\n\\n\\nShop\\n\\n\\nPartner Organizations\\n\\n\\nNational Symphony Orchestra\\n\\n\\nWashington National Opera\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nEducation\\n / \\n\\n\\nResources for Educators\\n / \\n\\n\\nDigital Resources Library\\n / \\n\\n\\nMedia & Interactives\\n / \\n\\n\\nYour Brain on Music\\n\\n\\nYBoM: Tearjerkers\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n                                    Music\\r\\n                                \\n\\r\\n                                    Science\\r\\n                                \\n\\r\\n                                    Popular Culture\\r\\n                                \\n\\n\\n\\n\\r\\n                        Your Brain on Music: Tearjerkers\\r\\n                            \\nPutting the \"Sad\" in Sad Songs\\n\\n\\n\\n\\nWarning:\\xa0this article contains excerpts from some of the saddest pieces of music ever written.\\n\\xa0\\n\\n\\n\\n\\n\\n\\n\\nLesson Content\\n\\n\\n\\n\\r\\n                                                Tearjerkers\\r\\n                                            \\n\\n\\n\\r\\n                                                Hall of Fame\\r\\n                                            \\n\\n\\n\\n\\n\\n\\n\\n\\nIntroduction\\nListen to the examples in the audio players below. You will hear the same song played two different ways. As you listen, think about each version and how it makes you feel.\\n\\n\\nDid you notice a difference between these two versions of the French folk tune “Frère Jacques”? Chances are the first version struck you as kind of snappy and happy. The second probably sounded all doomy and gloomy.\\nWhat changed? The first version was played in what is called a major key. The second version used a minor key. Using different keys is one way composers try to build certain feelings into their music. And for people who grow up listening to Western music—styles of music that started in Europe—minor keys appear to have special powers to give music a sad sound.\\nBut first you should know that brain and music research has proven a strong link exists between songs and feelings. And if you’re a music lover, you know that certain songs can sound “sad” and may put a lump in your throat or tears in your eyes. This is no accident. Composers use certain techniques to help their music express every kind of feeling, including sadness.\\nDifferent Cultures, Different Scales, Different Feelings\\nThe effect of using major and minor keys mainly holds true for people who grow up listening to Western music—musical styles that first developed in Europe. (Western countries include the United States, Canada, Australia, New Zealand, and most of the countries on the European continent.)\\nWestern music uses a seven-note scale. that might sound like this:\\n\\n\\n\\nPeople from other cultures may respond very differently. Why? Their music is based on different systems of notes. For example, musicians in Japan, China, West Africa, and many other cultures make traditional music using five-note scales, like this one:\\n\\n\\n\\nIn the Middle East and parts of Southern Europe, most music is created in a minor key. To people there, a minor-key song from the U.S. might not sound sad at all, while it might leave Americans wiping away tears.\\n\\n\\n\\n\\n\\n\\nMaking Sad\\nHere are the most common ways composers use to create moving, heartbreaking music. A mix of these methods is often used to put the “sad” in sad songs.\\nMajor and Minor Keys\\nIn music, keys refer to the set of notes a song is built around; the notes in a key work together to create melodies and harmonies. For example, Beethoven’s Fifth Symphony (maybe\\xa0the\\xa0most famous first four notes in classical music—da-da-da-DUM) is written in the key of C minor.\\xa0Give a listen:\\n\\n\\nLudwig van Beethoven: Mvt. 1 (excerpt) from Symphony No. 5 in C minor, Op. 67 (1808)\\n\\nWhen you listened to “Frère Jacques” a moment ago, you heard how switching from a major to minor key changes a song’s mood. That is why the key is an important tool composers choose to put emotion in their music.\\nScientific research finds that most listeners have similar reactions to music in major and minor keys. In general, most songs we consider upbeat or “happy” are written in major keys. And at least two out of three songs from Western countries are written in major keys, says Professor David Huron. Huron, a scientist at Ohio State University, studies the effects of music on the brain and body.\\nSongs that sound “sad” or moody often feature minor keys. This is not always the case, but in general it holds true. The difference from a major key helps communicate a darker mood to us. Try listening to some of your favorite songs, and guess if they are in a major or minor key.\\nTempo\\nTempo, the speed at which music is played, is another way composers create mood. Sing the song “Happy Birthday” at normal speed.\\nNow … sing … it … very … slowly.\\nQuite a difference, isn’t there? Sad songs usually move at a slower tempo—like someone taking a slow walk to brood about something.\\nFor example, the tempo for\\xa0Lacrimosa\\xa0from Mozart’s Requiem in D Minor is marked adagio — which means “slow and stately.” Most listeners describe this piece as sorrowful. Listen:\\n\\n\\nWolfgang Amadeus Mozart: Mvt. III \"Lacrimosa\" from Requiem KV626\\xa0(1791)\\n\\nMozart had good reason to write a sad song. He was very sick at the time and was sure he was dying. Sadly, he was right. The musical genius was still working on the song when he died. He was only 35 years old.\\nThat should make the rest of us sad, too. Imagine how much more great music Mozart would have written if he had lived a longer life.\\nTone and Musical Range\\nImagine any song played by a high-pitched flute. Now imagine the same tune tooted on a big tuba. Chances are the tuba will give the song a moodier feel.\\nSongwriters use different voices and instruments to help them set the mood of a song. For sad music, they will frequently use voices or instruments with a deeper, mellower sound. Also, sad songs often rely more on lower notes. Try singing “Twinkle, Twinkle Little Star” in high notes. Then sing it again using the lowest notes you can. How does the feeling of the song change? Listen to both versions in the audio player below:\\n\\n\\n\\nWhy do different note ranges have that effect? Think about how people speak when they are happy, and when they are feeling blue. When we’re sad, we usually speak in lower tones.\\nPhrasing\\nA musical phrase is a series of notes that feel connected. They are kind of like a sentence in a story. Most musical phrases have their own beginning, middle, and end. They link together to create the song.\\nSongwriters and musicians use phrasing to help communicate feelings in their music. A phrase that generally moves upward may signal hope or joy. A phrase that descends can signal the opposite—fear or despair.\\nListen to “Angel” by pop singer/songwriter Sarah McLachlan (below). Don’t worry about understanding the words. Just listen—and feel—how the musical phrases rise and fall.\\xa0This helps bring out the sad feelings in the song. Listen:\\n\\n\\n\\nSarah McLachlan: \"Angel\"\\xa0From Surfacing (1998)\\nContrast\\nOne of the gloomiest songs ever written is the third movement of Piano Sonata No. 2 in B-flat minor, Opus 35, by Frederic Chopin. It is better known as “Chopin’s Funeral March.” Perhaps you’ve heard it?\\n\\n\\n\\nMost people instantly recognize the mournful melody. But there is more to this famous tune than just doom and gloom.\\nYes, it is very slow and in a minor key. Yes, the main melody is played in low notes, and the phrasing seems to be heading straight for the graveyard. But about a minute into the song a surprising musical phrase rises up. And a while later, a gentler, sweet melody emerges. The march later returns to its darker beginning. It ends with the song’s well-known phrase. Play the whole movement again, listening for the more upbeat sections:\\n\\n\\nFrederic Chopin: Mvt. III from Piano Sonata No. 2 in B-flat minor, Opus 35\\xa0(1840)\\n\\nGood composers know the importance of building contrast into their music. To make a song really sad, it helps to include moments that sound hopeful. To bring out the joy in a major key, it may help to include a moody section in a minor key.\\nContrast is crucial in music and other forms of art. All loud or all soft, all happy or all sad, becomes predictable and boring. Contrast helps us hear—and feel—the emotions in music more strongly.\\n\\n\\n\\n\\n\\n\\nThe Science of Sad\\nFor about half of all people, sad songs are boring or just depressing. The other half, though, enjoy how sad music touches their emotions. And about one in ten listeners prefer moody songs, says Professor David Huron.\\nWhy do some people like a little heartbreak and a few tears in their tunes? Brain and music researchers are looking at two main ways sad music may actually bring comfort.\\nFirst, a sad person may feel lonely and cut off from other people. But a favorite sad song can suggest there is another person out there who understands what they are going through. This connection can help them feel less alone, says music professor Ian Cross of Cambridge University in England.\\nSecond, sad songs can trigger a physical response in some people. When a favorite pet dies, our best friend moves away, or something else makes us feel really sad, our bodies naturally release prolactin. It is a hormone—a chemical in our bodies that helps control how we feel and behave. Our bodies release it when we feel true grief or sadness. It shows up in our tears and other parts of our bodies during these times. (Interestingly, prolactin is absent if we cry from irritation, like when we chop onions.)\\nProfessor Huron’s research suggests prolactin helps us get through tough emotional times. It acts on our minds and bodies to help us deal with deep sadness. It keeps the feelings from spinning out of control and lets us function even though we may feel miserable. “It’s like Mother Nature’s way of wrapping her arms around you and saying, ‘There, there. Everything is okay,’” Huron says.\\nAccording to Huron, sad movies or sad songs can cause the release of prolactin, too. It brings the same feelings of comfort, though in these cases what triggers the prolactin is really just music or a made-up story.\\nSo next time you feel like having a good cry, turn on your favorite sad song and get out the tissues. You’ll feel better afterward—thanks to prolactin.\\nSadness in Speech and Songs\\n“Think about talking to a sad friend on the phone,” says Professor Huron. “How do they sound?” Based on scientific research, people express sadness in their voices in six ways. A sad person usually speaks:\\n\\nmore quietly;\\nmore slowly;\\nin a lower pitch than normal;\\nin a monotone—their tone of voice does not move up or down very much;\\nless clearly or by mumbling;\\nin darker, huskier tones—“Like they’re speaking through a pillow,” says Huron;\\n\\nComposers use similar signals when writing moody songs. For example, sad songs often are quieter, slower, and use lower notes than more upbeat music. Research suggests music can build in sadness by imitating emotional clues we use when we speak.\\nResearchers at Tufts University in Massachusetts recently identified other connections between emotions, speech patterns, and music. In an experiment, they asked actors to speak as if they were sad. The study found that the tone of voice came out in two specific tones. These tones matched what musicians call the “minor third.” Here is how the minor third sounds:\\n\\n\\n\\nThe minor third is an interval, or distance, between two musical notes that suggests sadness to most listeners.\\nThe experiment only tested English-speaking Americans. More studies are needed to see if these findings apply to other languages and cultures.\\n\\n\\n\\n\\n\\n\\n\\n\\nThe Sad Music Hall of Fame\\nThese audio players\\xa0contain excerpts from a few of the saddest pieces of music ever written. When you listen to them, try to pick out techniques the composer used to communicate sadness through music. Most importantly, listen to your feelings. What are they telling you about the music?\\n\\n\\nIt is widely believed that Richard Strauss wrote Metamorphosen as a statement of mourning for Germany\\'s destruction during the war, in particular as a elegy for devastating bombing of Munich, especially places such as the Munich Opera House.\\n\\nRichard Strauss: Excerpt from\\xa0Metamorphosen, Study for 23 Solo Strings\\xa0(1945)\\n\\n\\nSamuel Barber\\'s Adagio for Strings is a short instrumental piece for orchestra. The work is a slow, minor-key lament, which evokes a deep sadness in those who hear it. The Adagio was broadcast over the radio at the announcement of Franklin D. Roosevelt\\'s death, and since can be heard on many film and TV soundtracks, including Oliver Stone\\'s Oscar-winning film Platoon and David Lynch\\'s 1980 Oscar-nominated film The Elephant Man.\\n\\nSamuel Barber: Exerpt from Adagio for Strings (1936)\\n\\n\\nAdagio in G minor for violin, strings and organ continuo, is a neo-Baroque composition popularly attributed to the 18th-century Venetian master Tomaso Albinoni, but composed by the 20th-century musicologist and Albinoni biographer Remo Giazotto. The composition has also permeated popular culture, having been used as background music for such films as Gallipoli.\\n\\nRemo Giazotto (after Albinoni): Excerpt from Adagio in G minor\\xa0(1945)\\n\\n\\nJohn Williams composed the score for Schindler\\'s List. The composer was amazed by the film, and felt it would be too challenging. He said to director Stephen Spielberg, \"You need a better composer than I am for this film.\" Spielberg replied, \"I know. But they\\'re all dead!\"\\n\\nJohn Williams: \"Main Theme\" (excerpt) from Schindler\\'s List\\xa0(1993)\\n\\n\\nThe Symphony No. 3, Op. 36, also known as the Symphony of Sorrowful Songs, is a symphony in three movements composed by Henryk Górecki. Górecki said of the work, \"The Third Symphony is not about war; it\\'s not a Dies Irae; it\\'s a normal Symphony of Sorrowful Songs.\"\\n\\nHenryk Górecki: Mvt. III (excerpt) from Symphony No. 3, Op. 36 (1976)\\n\\n\\n\"Dido\\'s Lament\" is the commonly-used name for the noted aria, \"When I am laid in earth\", from the opera, Dido and Aeneas, by Henry Purcell.\\n\\nHenry Purcell: \"When I am laid in earth\" (excerpt) from Dido and Aeneas\\xa0(1688)\\n\\n\\nCantus is a meditation on death. Speaking on his reaction to Britten\\'s death, Pärt admitted, \"Why did the date of Benjamin Britten\\'s death touch such a chord in me? I had just discovered Britten for myself... for a long time I had wanted to meet Britten personally – and now it would not come to that.\"\\n\\nArvo Pärt: Excerpt from Cantus in Memoriam Benjamin Britten\\xa0(1977)\\n\\n\\nThe Requiem Mass in D minor (K. 626) by Wolfgang Amadeus Mozart was composed in Vienna in 1791 and left unfinished at the composer\\'s death. The \"Lacrimosa\" (tears) is part of the \"Dies Irae\" (Day of Wrath) sequence in the mass.\\n\\nWolfgang Amadeus Mozart: Mvt. III \"Lacrimosa\" from Requiem KV626\\xa0(1791)\\n\\n\\nThere have been several urban legends regarding \"Gloomy Sunday,\" mostly involving it being allegedly connected with various numbers of suicides, and radio networks reacting by purportedly banning the song. During World War II, the BBC banned Billie Holiday\\'s version of the song from being broadcast, as being detrimental to wartime morale, but allowed performances of instrumental versions. In 1968, some 35 years after writing the song, its composer Rezső Seress did commit suicide.`\\n\\nBillie Holiday: \"Gloomy Sunday\" (excerpt)\\xa0(1933)\\n\\n\\n\"Goin\\' Down Slow\" is a blues song written by St. Louis Jimmy Oden, originally released in 1941. The song alternates between sung and spoken passages, with the sung passages are the reflections of a dying man.\\n\\nSt. Louis Jimmy Oden: \"Goin\\' Down Slow\" (excerpt) (1941)\\n\\n\\n\"River\" is a song by Joni Mitchell, from her 1971 album Blue. In the song, Mitchell ruminates on the recent breakup of a romantic relationship. Christmas is nearing, and Mitchell longs to escape her emotional bonds, openly wishing \"I wish I had a river / I could skate away on\", a river so long she \"would teach my feet to fly.\"\\n\\nJoni Mitchell: \"River\" (excerpt) from Blue (1971)\\n\\n\\n\"Tears in Heaven\" is a ballad written by Eric Clapton and Will Jennings about the pain and loss Clapton felt following the death of his four-year-old son, Conor. The early 1990\\'s were extremely turbulent for Clapton. In August 1990 his manager and two of his roadies (along with fellow musician Stevie Ray Vaughan) were killed in a helicopter accident, and only seven months later came the death of his young son.\\n\\nEric Clapton & Will Jennings: \"Tears in Heaven\" (excerpt) from Rush (1992)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWriter\\nSean McCollum\\n\\n\\nEditor\\nLisa Resnick\\n\\n\\nProducer\\nKenny Neal\\n\\n\\nUpdated\\nJune 11, 2019\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n                        In This Series\\r\\n                    \\n\\n\\n\\n\\n\\n\\nMedia\\n\\r\\n                        Your Brain on Music: The Sound System Between Your Ears\\r\\n                    \\n\\n\\n\\nThe amazing sound system in the human brain helps explain why people everywhere fill their lives with music.\\n\\n\\nMusic\\nScience\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMedia\\n\\r\\n                        Your Brain on Music: Chills & Thrills\\r\\n                    \\n\\n\\n\\nCreators of spooky tunes know exactly what they are doing when they send shivers down the spines of listeners.\\n\\n\\nMusic\\nScience\\nPopular Culture\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMedia\\n\\r\\n                        Your Brain on Music: Earworms\\r\\n                    \\n\\n\\n\\nRecalling a favorite song in our imaginations can bring a private smile. But an earworm is different.\\n\\n\\nMusic\\nScience\\nPopular Culture\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nArticle\\n\\r\\n                        The Many Gifts of Music\\r\\n                    \\n\\n\\n\\nResearch shows that making music exercises the brain in ways science is only beginning to understand\\n\\n\\nMusic\\nLife Skills\\nAdvocacy\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nKennedy Center Education Digital Learning\\nEric Friedman\\xa0Director, Digital Learning\\nKenny Neal\\xa0Manager, Digital Education Resources\\nTiffany A. Bryant\\xa0Manager, Operations and Audience Engagement\\n\\nJoDee Scissors\\xa0Content Specialist, Digital Learning\\nConnect with us!\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\n\\n\\n\\n\\n\\n\\nGenerous support for educational programs at the Kennedy Center is provided by the U.S. Department of Education.\\nGifts and grants to educational programs at the Kennedy Center are provided by The Paul M. Angell Family Foundation; Bank of America; Capital One; The Morris and Gwendolyn Cafritz Foundation; Carnegie Corporation of New York; The Ednah Root Foundation; Harman Family Foundation; William R. Kenan, Jr. Charitable Trust; the Kimsey Endowment; The Kiplinger Foundation; Laird Norton Family Foundation; Lois and Richard England Family Foundation; Dr. Gary Mather and Ms. Christina Co Mather; The Markow Totevy Foundation; Dr. Gerald and Paula McNichols Foundation; The Morningstar Foundation; Myra and Leura Younker Endowment Fund; The Irene Pollin Audience Development and Community Engagement Initiatives;\\n\\n\\n\\n\\n\\n\\nPrince Charitable Trusts;\\xa0Dr. Deborah Rose and Dr. Jan A. J. Stolwijk; Rosemary Kennedy Education Fund; The Embassy of the United Arab Emirates; The Victory Foundation; The Volgenau Foundation; Volkswagen Group of America; Jackie Washington; GRoW @ Annenberg and Gregory Annenberg Weingarten and Family; Wells Fargo; and generous contributors to the Abe Fortas Memorial Fund and by a major gift to the fund from the late Carolyn E. Agger, widow of Abe Fortas. Additional support is provided by the National Committee for the Performing Arts..\\nThe content of these programs may have been developed under a grant from the U.S. Department of Education but does not necessarily represent the policy of the U.S. Department of Education. You should not assume endorsement by the federal government.\\n\\n\\n\\n\\n\\n\\n\\n\\nSite Footer\\n\\nInfo, Contact & Actions\\n\\n\\n\\n\\n\\nNews Room\\n\\n\\nCareers\\n\\n\\nAbout Us\\n\\n\\nRentals\\n\\n\\nGift Certificates\\n\\n\\nContact Us\\n\\n\\n\\n\\n\\n\\n\\r\\n                        Top\\r\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDirections & Policies\\n\\n\\nDirections & Parking\\n\\n\\nBox Office\\n\\n\\nPrivacy Statement\\n\\n\\nTerms & Conditions\\n\\n\\n\\n\\nSocial Media\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCopyright 1990-2024. All rights reserved.\\n\\n\\n\\n\\n\\n\\n\\nBy using this site, you agree to our\\xa0Privacy Policy\\xa0and\\xa0Terms & Conditions\\xa0which describe our use of cookies.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nReserve Tickets\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nReview Cart\\n\\n\\n\\n\\r\\n                                    You have 0 items in your cart.\\r\\n                                \\n\\n\\nYour cart is empty.\\n\\n\\nKeep Exploring\\nProceed to Cart & Checkout\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_key = next(iter(database))\n",
    "\n",
    "# Mostrar la clave y el valor asociado\n",
    "database[first_key[:200]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\u00C0-\\u00FF\\s.,!?;:'-]\", '', text)\n",
    "\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'https://www.kennedy-center.org/education/resources-for-educators/classroom-resources/media-and-interactives/media/music/your-brain-on-music/your-brain-on-music/your-brain-on-music-tearjerkers/': \"Your Brain on Music: Tearjerkers Skip to Main Content Navigation Kennedy Center Kennedy Center Page Navigation Whats On Visit Digital Stage Support Education Our Story Memorial Shop Partner Organizations National Symphony Orchestra Washington National Opera Utility Navigation Kennedy Center Utility Toggle Menu Page Navigation Whats On Visit Digital Stage Support Education Our Story Memorial Shop Partner Organizations National Symphony Orchestra Washington National Opera Education Resources for Educators Digital Resources Library Media Interactives Your Brain on Music YBoM: Tearjerkers Music Science Popular Culture Your Brain on Music: Tearjerkers Putting the Sad in Sad Songs Warning: this article contains excerpts from some of the saddest pieces of music ever written. Lesson Content Tearjerkers Hall of Fame Introduction Listen to the examples in the audio players below. You will hear the same song played two different ways. As you listen, think about each version and how it makes you feel. Did you notice a difference between these two versions of the French folk tune Frère Jacques? Chances are the first version struck you as kind of snappy and happy. The second probably sounded all doomy and gloomy. What changed? The first version was played in what is called a major key. The second version used a minor key. Using different keys is one way composers try to build certain feelings into their music. And for people who grow up listening to Western musicstyles of music that started in Europeminor keys appear to have special powers to give music a sad sound. But first you should know that brain and music research has proven a strong link exists between songs and feelings. And if youre a music lover, you know that certain songs can sound sad and may put a lump in your throat or tears in your eyes. This is no accident. Composers use certain techniques to help their music express every kind of feeling, including sadness. Different Cultures, Different Scales, Different Feelings The effect of using major and minor keys mainly holds true for people who grow up listening to Western musicmusical styles that first developed in Europe. Western countries include the United States, Canada, Australia, New Zealand, and most of the countries on the European continent. Western music uses a seven-note scale. that might sound like this: People from other cultures may respond very differently. Why? Their music is based on different systems of notes. For example, musicians in Japan, China, West Africa, and many other cultures make traditional music using five-note scales, like this one: In the Middle East and parts of Southern Europe, most music is created in a minor key. To people there, a minor-key song from the U.S. might not sound sad at all, while it might leave Americans wiping away tears. Making Sad Here are the most common ways composers use to create moving, heartbreaking music. A mix of these methods is often used to put the sad in sad songs. Major and Minor Keys In music, keys refer to the set of notes a song is built around; the notes in a key work together to create melodies and harmonies. For example, Beethovens Fifth Symphony maybe the most famous first four notes in classical musicda-da-da-DUM is written in the key of C minor. Give a listen: Ludwig van Beethoven: Mvt. 1 excerpt from Symphony No. 5 in C minor, Op. 67 1808 When you listened to Frère Jacques a moment ago, you heard how switching from a major to minor key changes a songs mood. That is why the key is an important tool composers choose to put emotion in their music. Scientific research finds that most listeners have similar reactions to music in major and minor keys. In general, most songs we consider upbeat or happy are written in major keys. And at least two out of three songs from Western countries are written in major keys, says Professor David Huron. Huron, a scientist at Ohio State University, studies the effects of music on the brain and body. Songs that sound sad or moody often feature minor keys. This is not always the case, but in general it holds true. The difference from a major key helps communicate a darker mood to us. Try listening to some of your favorite songs, and guess if they are in a major or minor key. Tempo Tempo, the speed at which music is played, is another way composers create mood. Sing the song Happy Birthday at normal speed. Now sing it very slowly. Quite a difference, isnt there? Sad songs usually move at a slower tempolike someone taking a slow walk to brood about something. For example, the tempo for Lacrimosa from Mozarts Requiem in D Minor is marked adagio which means slow and stately. Most listeners describe this piece as sorrowful. Listen: Wolfgang Amadeus Mozart: Mvt. III Lacrimosa from Requiem KV626 1791 Mozart had good reason to write a sad song. He was very sick at the time and was sure he was dying. Sadly, he was right. The musical genius was still working on the song when he died. He was only 35 years old. That should make the rest of us sad, too. Imagine how much more great music Mozart would have written if he had lived a longer life. Tone and Musical Range Imagine any song played by a high-pitched flute. Now imagine the same tune tooted on a big tuba. Chances are the tuba will give the song a moodier feel. Songwriters use different voices and instruments to help them set the mood of a song. For sad music, they will frequently use voices or instruments with a deeper, mellower sound. Also, sad songs often rely more on lower notes. Try singing Twinkle, Twinkle Little Star in high notes. Then sing it again using the lowest notes you can. How does the feeling of the song change? Listen to both versions in the audio player below: Why do different note ranges have that effect? Think about how people speak when they are happy, and when they are feeling blue. When were sad, we usually speak in lower tones. Phrasing A musical phrase is a series of notes that feel connected. They are kind of like a sentence in a story. Most musical phrases have their own beginning, middle, and end. They link together to create the song. Songwriters and musicians use phrasing to help communicate feelings in their music. A phrase that generally moves upward may signal hope or joy. A phrase that descends can signal the oppositefear or despair. Listen to Angel by pop singersongwriter Sarah McLachlan below. Dont worry about understanding the words. Just listenand feelhow the musical phrases rise and fall. This helps bring out the sad feelings in the song. Listen: Sarah McLachlan: Angel From Surfacing 1998 Contrast One of the gloomiest songs ever written is the third movement of Piano Sonata No. 2 in B-flat minor, Opus 35, by Frederic Chopin. It is better known as Chopins Funeral March. Perhaps youve heard it? Most people instantly recognize the mournful melody. But there is more to this famous tune than just doom and gloom. Yes, it is very slow and in a minor key. Yes, the main melody is played in low notes, and the phrasing seems to be heading straight for the graveyard. But about a minute into the song a surprising musical phrase rises up. And a while later, a gentler, sweet melody emerges. The march later returns to its darker beginning. It ends with the songs well-known phrase. Play the whole movement again, listening for the more upbeat sections: Frederic Chopin: Mvt. III from Piano Sonata No. 2 in B-flat minor, Opus 35 1840 Good composers know the importance of building contrast into their music. To make a song really sad, it helps to include moments that sound hopeful. To bring out the joy in a major key, it may help to include a moody section in a minor key. Contrast is crucial in music and other forms of art. All loud or all soft, all happy or all sad, becomes predictable and boring. Contrast helps us hearand feelthe emotions in music more strongly. The Science of Sad For about half of all people, sad songs are boring or just depressing. The other half, though, enjoy how sad music touches their emotions. And about one in ten listeners prefer moody songs, says Professor David Huron. Why do some people like a little heartbreak and a few tears in their tunes? Brain and music researchers are looking at two main ways sad music may actually bring comfort. First, a sad person may feel lonely and cut off from other people. But a favorite sad song can suggest there is another person out there who understands what they are going through. This connection can help them feel less alone, says music professor Ian Cross of Cambridge University in England. Second, sad songs can trigger a physical response in some people. When a favorite pet dies, our best friend moves away, or something else makes us feel really sad, our bodies naturally release prolactin. It is a hormonea chemical in our bodies that helps control how we feel and behave. Our bodies release it when we feel true grief or sadness. It shows up in our tears and other parts of our bodies during these times. Interestingly, prolactin is absent if we cry from irritation, like when we chop onions. Professor Hurons research suggests prolactin helps us get through tough emotional times. It acts on our minds and bodies to help us deal with deep sadness. It keeps the feelings from spinning out of control and lets us function even though we may feel miserable. Its like Mother Natures way of wrapping her arms around you and saying, There, there. Everything is okay, Huron says. According to Huron, sad movies or sad songs can cause the release of prolactin, too. It brings the same feelings of comfort, though in these cases what triggers the prolactin is really just music or a made-up story. So next time you feel like having a good cry, turn on your favorite sad song and get out the tissues. Youll feel better afterwardthanks to prolactin. Sadness in Speech and Songs Think about talking to a sad friend on the phone, says Professor Huron. How do they sound? Based on scientific research, people express sadness in their voices in six ways. A sad person usually speaks: more quietly; more slowly; in a lower pitch than normal; in a monotonetheir tone of voice does not move up or down very much; less clearly or by mumbling; in darker, huskier tonesLike theyre speaking through a pillow, says Huron; Composers use similar signals when writing moody songs. For example, sad songs often are quieter, slower, and use lower notes than more upbeat music. Research suggests music can build in sadness by imitating emotional clues we use when we speak. Researchers at Tufts University in Massachusetts recently identified other connections between emotions, speech patterns, and music. In an experiment, they asked actors to speak as if they were sad. The study found that the tone of voice came out in two specific tones. These tones matched what musicians call the minor third. Here is how the minor third sounds: The minor third is an interval, or distance, between two musical notes that suggests sadness to most listeners. The experiment only tested English-speaking Americans. More studies are needed to see if these findings apply to other languages and cultures. The Sad Music Hall of Fame These audio players contain excerpts from a few of the saddest pieces of music ever written. When you listen to them, try to pick out techniques the composer used to communicate sadness through music. Most importantly, listen to your feelings. What are they telling you about the music? It is widely believed that Richard Strauss wrote Metamorphosen as a statement of mourning for Germany's destruction during the war, in particular as a elegy for devastating bombing of Munich, especially places such as the Munich Opera House. Richard Strauss: Excerpt from Metamorphosen, Study for 23 Solo Strings 1945 Samuel Barber's Adagio for Strings is a short instrumental piece for orchestra. The work is a slow, minor-key lament, which evokes a deep sadness in those who hear it. The Adagio was broadcast over the radio at the announcement of Franklin D. Roosevelt's death, and since can be heard on many film and TV soundtracks, including Oliver Stone's Oscar-winning film Platoon and David Lynch's 1980 Oscar-nominated film The Elephant Man. Samuel Barber: Exerpt from Adagio for Strings 1936 Adagio in G minor for violin, strings and organ continuo, is a neo-Baroque composition popularly attributed to the 18th-century Venetian master Tomaso Albinoni, but composed by the 20th-century musicologist and Albinoni biographer Remo Giazotto. The composition has also permeated popular culture, having been used as background music for such films as Gallipoli. Remo Giazotto after Albinoni: Excerpt from Adagio in G minor 1945 John Williams composed the score for Schindler's List. The composer was amazed by the film, and felt it would be too challenging. He said to director Stephen Spielberg, You need a better composer than I am for this film. Spielberg replied, I know. But they're all dead! John Williams: Main Theme excerpt from Schindler's List 1993 The Symphony No. 3, Op. 36, also known as the Symphony of Sorrowful Songs, is a symphony in three movements composed by Henryk Górecki. Górecki said of the work, The Third Symphony is not about war; it's not a Dies Irae; it's a normal Symphony of Sorrowful Songs. Henryk Górecki: Mvt. III excerpt from Symphony No. 3, Op. 36 1976 Dido's Lament is the commonly-used name for the noted aria, When I am laid in earth, from the opera, Dido and Aeneas, by Henry Purcell. Henry Purcell: When I am laid in earth excerpt from Dido and Aeneas 1688 Cantus is a meditation on death. Speaking on his reaction to Britten's death, Pärt admitted, Why did the date of Benjamin Britten's death touch such a chord in me? I had just discovered Britten for myself... for a long time I had wanted to meet Britten personally and now it would not come to that. Arvo Pärt: Excerpt from Cantus in Memoriam Benjamin Britten 1977 The Requiem Mass in D minor K. 626 by Wolfgang Amadeus Mozart was composed in Vienna in 1791 and left unfinished at the composer's death. The Lacrimosa tears is part of the Dies Irae Day of Wrath sequence in the mass. Wolfgang Amadeus Mozart: Mvt. III Lacrimosa from Requiem KV626 1791 There have been several urban legends regarding Gloomy Sunday, mostly involving it being allegedly connected with various numbers of suicides, and radio networks reacting by purportedly banning the song. During World War II, the BBC banned Billie Holiday's version of the song from being broadcast, as being detrimental to wartime morale, but allowed performances of instrumental versions. In 1968, some 35 years after writing the song, its composer Rezs Seress did commit suicide. Billie Holiday: Gloomy Sunday excerpt 1933 Goin' Down Slow is a blues song written by St. Louis Jimmy Oden, originally released in 1941. The song alternates between sung and spoken passages, with the sung passages are the reflections of a dying man. St. Louis Jimmy Oden: Goin' Down Slow excerpt 1941 River is a song by Joni Mitchell, from her 1971 album Blue. In the song, Mitchell ruminates on the recent breakup of a romantic relationship. Christmas is nearing, and Mitchell longs to escape her emotional bonds, openly wishing I wish I had a river I could skate away on, a river so long she would teach my feet to fly. Joni Mitchell: River excerpt from Blue 1971 Tears in Heaven is a ballad written by Eric Clapton and Will Jennings about the pain and loss Clapton felt following the death of his four-year-old son, Conor. The early 1990's were extremely turbulent for Clapton. In August 1990 his manager and two of his roadies along with fellow musician Stevie Ray Vaughan were killed in a helicopter accident, and only seven months later came the death of his young son. Eric Clapton Will Jennings: Tears in Heaven excerpt from Rush 1992 Writer Sean McCollum Editor Lisa Resnick Producer Kenny Neal Updated June 11, 2019 In This Series Media Your Brain on Music: The Sound System Between Your Ears The amazing sound system in the human brain helps explain why people everywhere fill their lives with music. Music Science Media Your Brain on Music: Chills Thrills Creators of spooky tunes know exactly what they are doing when they send shivers down the spines of listeners. Music Science Popular Culture Media Your Brain on Music: Earworms Recalling a favorite song in our imaginations can bring a private smile. But an earworm is different. Music Science Popular Culture Article The Many Gifts of Music Research shows that making music exercises the brain in ways science is only beginning to understand Music Life Skills Advocacy Kennedy Center Education Digital Learning Eric Friedman Director, Digital Learning Kenny Neal Manager, Digital Education Resources Tiffany A. Bryant Manager, Operations and Audience Engagement JoDee Scissors Content Specialist, Digital Learning Connect with us! Generous support for educational programs at the Kennedy Center is provided by the U.S. Department of Education. Gifts and grants to educational programs at the Kennedy Center are provided by The Paul M. Angell Family Foundation; Bank of America; Capital One; The Morris and Gwendolyn Cafritz Foundation; Carnegie Corporation of New York; The Ednah Root Foundation; Harman Family Foundation; William R. Kenan, Jr. Charitable Trust; the Kimsey Endowment; The Kiplinger Foundation; Laird Norton Family Foundation; Lois and Richard England Family Foundation; Dr. Gary Mather and Ms. Christina Co Mather; The Markow Totevy Foundation; Dr. Gerald and Paula McNichols Foundation; The Morningstar Foundation; Myra and Leura Younker Endowment Fund; The Irene Pollin Audience Development and Community Engagement Initiatives; Prince Charitable Trusts; Dr. Deborah Rose and Dr. Jan A. J. Stolwijk; Rosemary Kennedy Education Fund; The Embassy of the United Arab Emirates; The Victory Foundation; The Volgenau Foundation; Volkswagen Group of America; Jackie Washington; GRoW Annenberg and Gregory Annenberg Weingarten and Family; Wells Fargo; and generous contributors to the Abe Fortas Memorial Fund and by a major gift to the fund from the late Carolyn E. Agger, widow of Abe Fortas. Additional support is provided by the National Committee for the Performing Arts.. The content of these programs may have been developed under a grant from the U.S. Department of Education but does not necessarily represent the policy of the U.S. Department of Education. You should not assume endorsement by the federal government. Site Footer Info, Contact Actions News Room Careers About Us Rentals Gift Certificates Contact Us Top Directions Policies Directions Parking Box Office Privacy Statement Terms Conditions Social Media Copyright 1990-2024. All rights reserved. By using this site, you agree to our Privacy Policy and Terms Conditions which describe our use of cookies. Reserve Tickets Review Cart You have 0 items in your cart. Your cart is empty. Keep Exploring Proceed to Cart Checkout\",\n",
       " 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3779798/': '403403 Forbidden',\n",
       " 'https://www.psypost.org/new-research-uncovers-atonal-musics-distinct-emotional-and-neural-effects/': '403 Forbidden 403 Forbidden nginx',\n",
       " 'https://online.ucpress.edu/mp/article/40/3/202/195230/The-Perceptual-and-Emotional-Consequences-of': 'Just a moment...Enable JavaScript and cookies to continue',\n",
       " 'https://dl.acm.org/doi/fullHtml/10.1145/3461615.3485419': \"When Emotions are Triggered by Single Musical Notes: Revealing the Underlying Factors of Auditory-Emotion Associations When Emotions are Triggered by Single Musical Notes: Revealing the Underlying Factors of Auditory-Emotion Associations Patrick O'Toole, School of Computer Science and Information Technology, University College Cork, Ireland, patrick.otooleumail.ucc.ie Donald Glowinski, Department of Psychology and Educational Sciences, University of Geneva, Switzerland, donald.glowinskiunige.ch Ian Pitt, School of Computer Science and Information Technology, University College Cork, Ireland, ianpcs.ucc.ie Maurizio Mancini, Department of Computer Science, Sapienza University of Rome, Italy, m.mancinidi.uniroma1.it DOI: ICMI '21 Companion: Companion Publication of the 2021 International Conference on Multimodal Interaction, Montréal, QC, Canada, October 2021 Can emotion be experienced when the auditory sense is stimulated by a single musical note Q1, and do variables such as musical skills, age, and personality traits have an influence in auditory-emotion associations Q2? An experiment was conducted, in which 130 participants were asked to listen to single musical notes and rate their experienced emotional state. They also had to rate their musical proficiency, sound sensitivity, strongest learning style, and complete a reduced version of the Big-Five personality test BFI-10. Results regarding Q1 show a correlation between lower notes and sadness, and higher notes and joy, confirming previous auditory-emotion association research, while presenting new knowledge into how emotion associates with single musical notes. Results regarding Q2 show that musical proficiency low vs high, learning style aural vs physical, personality level of Conscientiousness had an effect on how participants emotionally experienced single musical notes. The results presented in this study will provide a starting point that can help develop a new auditory-visual framework that uses understandings on emotion, personality and other variables in the development of more personalised human-computer interfaces. This new framework can be used in applications that can help in learning to paint or play an instrument; promoting positive mental health, or exploring new forms of creative expression e.g., writing a song with a paint brush as the instrument or painting a picture with a piano as your brush. CCS Concepts: Human-centered computing Sound-based input output; Interaction design process and methods; Applied computingSound and music computing; Social and professional topics User characteristics; Keywords: auditory-emotion associations, multi-modal interactions, music, personality ACM Reference Format: Patrick O'Toole, Donald Glowinski, Ian Pitt, and Maurizio Mancini. 2021. When Emotions are Triggered by Single Musical Notes: Revealing the Underlying Factors of Auditory-Emotion Associations. In Companion Publication of the 2021 International Conference on Multimodal Interaction ICMI '21 Companion, October 1822, 2021, Montréal, QC, Canada. ACM, New York, NY, USA 8 Pages. 1 INTRODUCTION This paper presents an experiment to help gain a deeper understanding into associations between single musical notes and emotions, and what impact different individual variables, such as personality, musical experience and learning style can have on auditory-emotion associations. Emotion and personality have become popular areas of research in recent years, especially in relation to technology 12, 33. With a great amount of personal data being captured by people's devices, companies are using this data to understand their users and personalise tools and products to each user. Multi-modal interaction is an area that can benefit from adopting more personalised approaches to how we form associations between our senses 18, 30. Interesting insights from a study, that trained participants in sound-colour associations using an ad-hoc program, while also investigating the association between sound and emotion of participants, were found. The fore-mentioned study found a correlation between very basic emotions sadness and joy and basic auditory stimuli lower and higher pitch, but not at a significant level and with a low testing sample 31. The motivation for our paper is to explore the understandings of associations between single musical notes and emotion, and if individual variables can play an important part in the process of auditory-emotion associations. With this new understanding, an improved model of auditory-visual associations can be applied in designing human-computer interfaces, one that takes account of emotion as well as personality, age, gender, and other variables. Figure 1 highlights the research of single musical notes-emotion associations, that is presented in this paper, as part of a larger framework of auditory-emotion-colour associations. This paper will help contribute to this larger framework of auditory-emotion-visual associations and contribute to future designs of intelligent and personalised human-computer interfaces, that can harness the power of multi-modal associations in creative and artistic digital environments. Figure 1: The work presented in the paper is highlighted by the dotted line: while cross-modal melody-emotion-colour and melody-colour associations are widely studied 20, 29, 32, 36, 37, 38, 39, 40, 42, we focus on single note-emotion associations by also looking at the individual variables in Section 2.2, in the larger framework of studying sound-emotion-colour associations. 2 BACKGROUND 2.1 Auditory-Emotion Research Previous research into associations between auditory stimuli and emotion has been mostly situated in auditory-visual cross-modal association research, that mainly explores the role of emotion in this relationship, mostly using musical excerpts instead of single musical notes 4, 6, 21, 28, 37, 46. Palmer et al. present the emotional meditation hypothesis, which is understood to be, when people listen to music, they have emotional responses and pick colors with similar emotional content 32. The study from Palmer et al., and other studies have provided interesting insights into how auditory stimuli is perceived emotionally in relation to colors, with music in a major scale and at a faster tempo to be perceived lighter in colour and happier, with the opposite being true for a minor scale 32, 39, 43. Other studies have focused solely on the auditory-emotion associations, however, these studies like the ones mentioned above focus on musical excerpts and not basic auditory stimuli 27, 40. Very few studies have been conducted on the association between basic auditory stimuli, like single musical notes, and emotion 2, 26, 37. Like Palmer et al., Spence also supports emotion mediation as one of the key factors in cross-modal correspondences, not just for complex auditory stimuli but also more simple stimuli 37. Comparing simple auditory stimuli to more complex stimuli shows that emotion mediation counts for less variance in the empirical matching data, and therefore elicits less pronounced perceived emotion 37. If we can understand auditory-emotion associations in a similar way to auditory-visual associations, that are mediated by emotion, lower notes darker colours should associate with negative emotions and higher notes lighter colours with positive emotions 29, 36. Studies on the impact of different emotion models has been carried out in research around auditory-emotion associations, with three emotion models highlighted Basicdiscrete, dimensional and musically-induced 40, 45. While the musically-induced emotion model would seem appropriate for a study on single musical note-emotion associations, the comparative test of these models and also information on personality bias help formulate the best approach for the experiment presented in this paper. The study by Zentner et al., showed that, compared to the other two models, the basic emotion model performed rather well when rating perceived emotions, even if the musically-induced model was more consistent 45. In another study, the dimensional model performed better than both the basic and musically-induced emotion one in the discrimination of musical excerpts. However, Personality-related differences were the most pronounced in the case of the discrete emotion model 40. Three different studies on emotion words expressed when listening to music stimuli, show that happiness, sadness, anger and fear were among the top choices across all three studies 23. Taking into account the studies presented above, and bearing in mind that our study focuses on single musical notes rather than musical excerpts, and includes personality traits as an independent variable to be analysed, a basic emotion model joy, sadness, anger and fear is proposed. 2.2 Individual Variables In this paper, we also seek to understand how twelve individual variables Age, Gender, Musical Experience, Sound Sensitivity, Auditory-to-Other-Sense, Other-Sense-to-Auditory, Learning Style and the Big Five personality traits BFI of Openness, Conscientiousness, Extraversion, Agreeableness and Neuroticism, discussed in this section, can impact on the associations between single musical notes and emotion. 2.2.1 Personality traits. The relationship between personality traits and emotional responses to music is well researched. Studies have found significant correlations between the traits NeuroticismExtraversion and positivenegative emotions 3, 8, 22. ChamorroPremuzic Furnham found that personality and intelligence can be a factor on how people use music. A person with a high IQ and high Extraversion might use music in a rational cognitive way, while someone with high Neuroticism and low Conscientiousness might use music for emotional regulation 8. In another study, Neuroticism was found to significantly map to all negative emotions, while Extraversion significantly mapped to the positive emotions, interest and enjoyment as well as the negative emotion shyness 22. From a review on present literature on the correlation between basic emotions and personality traits, limited findings regarding the traits of Openness to Experience, Conscientiousness and Agreeableness were found 15. The Big Five personality test is a widely adopted test used in studies relating to personality traits. It is simple and easy to interpret, and is also an effective way to understand the personality traits of an individual. Rammstedt and John conducted research into the accuracy of the BFI-10 test using only 10 questions and found it sufficient to use in a research settings with limited time constraints, compared to the BFI-44 test using 44 questions 34. 2.2.2 Musical vs Non-Musical Experience. A study by Manno et al., investigated how musicians and non-musicians identify emotion in music. Music uses Temporal Fine Structures TFS and Envelope ENV modulation to resolve emotion in music, however the exact contributions of TFS and ENV is not known. The study showed that TFS is essential in identifying emotion in music and that there is a difference in how much TFS is used by musicians and non-musicians. Non-musicians use less fine structure information and have reduced emotional resolvability curves compared to musicians 27. While the study above shows that musical experience can have a difference in how much TFS is used in identifying emotion in music, it is unclear if the same logic can be adopted when identifying emotion from single musical notes. A study on expressive intentions with single piano notes, shows that musical expertise has no mean effect on performers when tested on the four acoustical parameters of pitch, intensity, articulation and rhythmic density, with both musicians and non-musicians using these acoustic parameters in very similar ways when listening to a single piano note 2. 2.2.3 Age and Gender. Studies show that age can have an impact on how we associate between our senses and how we use emotion in response to stimuli, and that it can change over time 21, 35, 44. Hunter et al., using two variants of an emotional Stroop task, found that older adults can match congruent cross-modal stimuli just as well as younger adults however, with incongruent stimuli, the older adults performed worse than their younger counterparts 21. Older adults tend to weaken the ability to perceive negative emotions the older they get 35, this can be caused by the fact they tend to remove problematic relationships and avoid interpersonal conflict, leading to a more positive social environment 1, 5. As well as age, studies into the role of gender in auditory-emotion associations research has shown some interesting insights. Studies between men and women with regards to both uni and multi sensory emotional stimuli have shown that women are more accurate than men in recognition of emotional prosody 10, 24, 41. 2.2.4 Other Variables. Sound sensitivity, in general and when sound is triggered as the primary and secondary source, are also investigated in this paper. Misophonia is a condition characterized by heightened emotional reactivity to common repetitive sounds, accompanied by difficulties responding to these sounds and associated impairment in functioning 7. A study on the relationship between the Neuroticism trait and Misophonia, with regard to the role of emotion regulation found that difficulties with emotion regulation and Neuroticism were significantly positively correlated with symptoms of misophonia 7. Past research in auditory-visual cross-modal associations and chromaesthesia have also informed our understanding of the way in which perception operates between auditoryother sense and other senseauditory with regard to sound sensitivity 11, 26, 36. Seven learning-style terms from Gardner's Theory of Multiple Intelligences Aural, Visual, Logical, Verbal, Physical, Social Interpersonal and Solitary Intrapersonal have been used to understand the different ways people learn and take in information 16. While the method used in our study to understand learning styles relies on the participants perception of the strongest learning style, and not assessed with a well-known method, like the BFI test for personality traits, some interesting insights that can inform future work is expected. 3 EXPERIMENT This experiment looks to understand associations between single musical notes and basic emotions, and how other independent variables impact these associations, with two specific questions in mind: Q1 - Can emotion be experienced from a single musical note and if so, how basic a level is the emotional perception that is experienced? Q2 - Is there a significant correlation between auditory-emotion choices when factoring in the twelve independent variables mentioned in Section 2.2? 3.1 Participants 130 people female 95, male 34, other 1 participated in the online survey, with participants identifying with the following age groups: 35-44 38, 24-34 32, 45-55 29, 55-64 14, 18-24 9, over 65 6 and under 18 2. Information was also gathered on participants musical experience 82 with musical experience and 18 with no experience and creativeness 61, regularly partaking in a creative hobby; 24, not so regularly; and 15, with no creative hobby. While musical experience was used as one of the individual variables that could impact the emotion response to auditory stimuli, the questions regarding musical instruments played by participants and their level of creative expression was used to gather an extra layer of understanding to the results of the experiment. 3.2 Sound and Emotion Stimuli In this experiment, the auditory stimuli were recorded on the Logic Pro X software using a Fender Telecaster electric guitar as the instrument. Each note was recorded on a mono track with each note lasting 6 seconds with a smooth short fade at the end of each clip. A basic EQ, compressor and room reverb are used to obtain a more natural sound, with each sound file rendered to an mp3 file with the normalised function turned on. The envelope of the recorded notes consist of a sharp attack to the maximum amplitude, with a steady decay as the note rings out. As this was an online survey, we had no control of the absolute volume participants listened to the stimuli, but asked them to set it to a comfortable listening level. The first octave of the guitar was chosen to elicit the auditory stimuli, from note E2 82.41Hz to note D3 155.6Hz. Final Cut Pro was used to create short video files with a white background with black text counting down from three, with audio stimuli playing on zero. These video files provided better functionality in Limesurvey 1, than audio only files and also added a visual instruction to participants. For the emotion stimuli, the four emotion words, sadness, anger, fear and joy were used. These emotions are taken from the discrete emotion model mentioned in Section 2.1. 3.3 Procedure The online survey was distributed through the University College Cork survey mailing list, as well as being shared on LinkedIn and Twitter. Once participants clicked on the survey link, they landed on the welcome page and were presented with a detailed explanation of the survey, as well as contact information of the researchers, if they had any questions regarding the survey and could click Next to agree to start the survey. The survey was broken up into four sections: General Information, Personality Test, Cross-modal Association Questions and Auditory-emotion Questions. The survey is described in following four sections. 3.3.1 General Questions Section. Each section was displayed on a separate page with participants instructed to click the Next button to move to the next section. The first section contained five questions regarding age, gender, musical ability, instruments played this question only appeared if the participant had stated they had musical experience in the previous question and creative hobbies. 3.3.2 Personality Test Section. This section involved the participants taking the short Big Five personality test BFI-10. Participants responded to ten questions on a five point Likert scale ranging from Strongly Disagree to Strongly Agree. These questions were randomised to avoid any bias in the survey. After the ten questions were answered, participants could consent to share their email address to get their BFI-10 scores sent to them at a later time. If consent was given, the participant could input their email address on the next page. 3.3.3 Cross-modal Association Section. The third section presented four questions, with the first three designed to gain an understanding of the participants relationship with sound, and how other senses impact and are impacted by auditory stimuli. The fourth question looked to find what learning style participants associated with their style of learning. The participants rated the first three questions, between 1 weak and 5 strong in sensitivitysensation. The first question asked participants to rate their sensitivity to noisesound; the next two questions asked participants to rate the sensation strength in other senses when the auditory sense is the primary trigger i.e., when a bell is rung and triggers sensation, and in the auditory sense when the other sense is the primary trigger i.e., when a flash of light triggers sensation. For the last question participants were given the options of Visual, Logical, Aural, Verbal, Physical, Social Interpersonal and Solitary Interpersonal learning styles from Section 2.2.4, and asked to choose their top three, in order of perceived strongest to weakest. 3.3.4 Auditory-emotion Questions Section. The final section contained twelve questions presented in randomised order, to avoid selection bias. Each question contained a nine second video, which instructed participants to press play when ready. The video presented a count down from three with the auditory stimuli playing on zero, giving the participant time to fully listen to the note played. As mentioned in Section 3.2, the first octave of the guitar was used for the auditory stimuli. They were informed to listen once and to choose an emotion word from the options presented Sadness, Joy, Anger, Fear. Figure 2: This figure shows the percentage between the four emotion words that participants chose for each musical note. Sadness significantly associated with the lower notes, with Joy significantly associating with the higher notes. Once the twelve sound-emotion questions were answered, they were directed to submit the survey and a conclusion page was displayed thanking participants for taking part. 3.4 Data Handling and Analysis The survey data was stored within the Limesurvey application running from the researcher's hosting site. All data was anonymised and information on IP addresses, date stamp and referrer URLs were not collected. Email addresses were collected only from the participants who consented to leave it for the purpose of sharing the results of the personality test. The email data was deleted once the results were obtained and emailed to the participants. To answer Q1, a chi-square test was conducted on the cross-table Note by Emotion. The chi-square test was significant 2 33 n 1560 274.39, p .001, with a small effect size Cramer's V .24. Table 1: Results of the chi-square test that was conducted on the cross-table Note-by-Emotion. The chi-square test was significant 2 33 n 1560 274.39, p .001, with a small effect size Cramer's V .24. The significant ARSs are highlighted in bold. Emotion Note Sadness Anger Fear Joy D Count 21a 16a, b 31b 62c Adj. Res. -5.586 -0.593 0.217 6.664 D Count 25a 26b 31b 48b Adj. Res. -4.835 2.044 0.217 3.654 C Count 39a 8a 30a, b 53b Adj. Res. -2.206 -2.703 0.000 4.729 C Count 29a 13a 29a 59b Adj. Res. -4.084 -1.384 -0.217 6.019 B Count 48a 13a 26a 43a Adj. Res. -0.516 -1.384 -0.870 2.580 A Count 46a 20a 32a 32a Adj. Res. -0.892 0.461 0.435 0.215 A Count 52a 25a 32a 21a Adj. Res. 0.235 1.780 0.435 -2.150 G Count 75a 12b 27a, b 16b Adj. Res. 4.554 -1.648 -0.652 -3.224 G Count 73a 20a, b 23b, c 14c Adj. Res. 4.178 0.461 -1.522 -3.654 F Count 69a 19a 36a 6b Adj. Res. 3.427 0.198 1.305 -5.374 F Count 74a 14a, b 32a 10b Adj. Res. 4.366 -1.121 0.435 -4.514 E Count 58a 33a 31a 8b Adj. Res. 1.361 3.890 0.217 -4.944 To answer Q2, a multinomial stepwise multiple regression model was carried out in which the dependent variable was the single musical notes. Using the variables obtained from the data in the survey as models, Age, Gender, Musical Experience, Sound Sensitivity, Auditory-to-Other-Sense, Other-Sense-to-Auditory, Learning Style and the five personality traits of Openness, Conscientiousness, Extra-version, Agreeableness and Neuroticism were analysed. Table 2: Result of multinomial stepwise multiple regression model. Only the significant predictors are reported. The reference emotion is always Joy. Estimate Std. Error Wald Sig. Odds ratio 95 Conf. Int. L Bound U Bound Note: C Anger Male 1.946 0.811 5.762 .016 7.000 1.429 34.286 Fear Male 1.302 0.508 6.573 .010 3.675 1.359 9.940 Note: C Anger Aural 1.946 0.886 4.818 .028 7.001 1.232 39.766 Anger Physical 1.946 0.976 3.976 .046 7.001 1.034 47.418 Note: A Sadness Proficiency -1.034 0.324 10.186 .001 .355 .188 .671 Anger Proficiency -0.825 0.365 5.102 .024 .438 .214 .897 Anger Conscientiousness -0.051 0.024 4.550 .033 .950 .906 .996 Fear Proficiency -1.042 0.353 8.728 .003 .353 .177 .704 Note: G Anger age -0.817 0.360 5.146 .023 .442 .218 .895 Fear age -0.853 0.307 7.746 .005 .426 .234 .777 Note: G Anger age -1.095 0.345 10.084 .001 .335 .170 .658 Note: E Anger sensitivesound 0.836 0.373 5.022 .025 2.308 1.111 4.795 3.5 Results 3.5.1 Q1 - Auditory-emotion association. For Q1, the results in Table 1 show that very basic emotion can be experienced from basic auditory stimuli, like a single musical note. For four out of five of the lowest notes E,F,F,G,G, Table 1 shows that the adjusted standardised residual ASR scores are significantly higher for Sadness. The one exception was the lowest note E where Anger has a higher ASR score but not at a significant level; however, Sadness was chosen by most participants, but not at a significant level. For the higher notes, results show that the four highest notes C,C,D,D are significantly higher for Joy in the ASR scores. Table 1 also highlights that only the emotions of Joy and Sadness found significance, either positively or negatively in ASR scores, that could suggest very basic emotion associations to single musical notes. Results show that for notes A,A, and B, which are placed in the middle of the octave of notes tested, no significant statistics are shown. 3.5.2 Q2 - Impact of Independent Variables on Sound-emotion Association. Results pertaining to Q2 highlighted some interesting insights. Q2 looked at how the individual variables, mentioned in Section 2.2, can affect the emotion choice for each single musical note. Analysis was performed on each note, and Table 2 shows significant results at p .05 where the individual variables had an impact on the association between single musical notes and emotion. As shown in Table 2, six out of the twelve musical notes showed statistical significance in relation to one or more predictors. The odds ratio column in Table 2 represents the relative likelihood of each predictor type yielding a choice for a particular emotion. For example, Table 2 shows that a person with a higher sensitivity to sound is 2.308 times more likely to choose Anger than Joy the emotion used as a reference in relation to the E note. For individual variables with an odds ratio of less than 1, the predictor is less likely to choose the stated emotion than the referenced emotion Joy, i.e., participants with musical proficiency are less likely to experience Sadness, Anger and Fear compared to Joy. 3.6 Discussion 3.6.1 Q1 - Sound-emotion Association. Similar to the findings of O'Toole et al., associations between basic auditory stimuli and emotion can be viewed at a very basic level of emotional perception 31. The results from the chi square test, illustrated in Table 1, show a significant association between Lower-notesSadness and Higher-notesJoy. In Section 2.1, research on different emotion models were presented, with the basicdiscrete model considered the most appropriate for an experiment using single musical notes and for perceiving rather than feeling emotions 45. For future research, adopting a multi-modal approach that can understand multiple features from auditory stimuli would be beneficial. However for this study on basic auditory stimuli, results show a basic emotion choice for single musical notes, validating the use of the basic emotion model in this experiment. With the three notes A, A, B in the middle of the octave that showed no significance, all three notes had Sadness as the most chosen emotion. A Study by Chau et al. has shown that the timbre of an instrument can impact the emotion response when hearing a sound. Results showed that the guitar rated higher for negative emotional characteristics compared to a piano which was emotionally neutral and instruments like a vibraphone or marimba which was emotionally positive 9. Findings from another study found that timbre independently affects the perception of emotions in music after controlling for other acoustic, cognitive and performance factors 19 While timbre is one of many acoustic properties that can impact the emotion response to sound, if we are analysing single musical notes that lack tempo, rhythm and modes, it could have a bigger impact on how a person responds to sound emotionally. To answer Q1, emotion can be experienced from basic auditory stimuli, such as a single musical note at a very basic level of emotion perception. Without melody, harmony, rhythm, modes and other audio features a single note can be perceived to be mostly happy or sad and this is mostly dependant on pitch. 3.6.2 Q2 - Independent Variables Impact on Sound-emotion Association. Q2 investigated how different individual variables can impact a participants emotion word choices. In Table 2, significant scores in seven out of twelve individual variables across six of the twelve musical notes were found. Conscientiousness provided a significant negative correlation with Anger on the note A. This result would fit the personality trait. Previous studies have shown that the Conscientiousness trait is positively associated with the optimistic-conventional dimension in relation to musical preference 14. Studies have shown that a person high in Conscientiousness is likely to; like high tempo music in a major key rather than low tempo in the minor key 14; use music in a more cognitive rather than an emotional way 8; and usually can regulate or control impulses better 13. Table 2 shows that musically proficient participants significantly chose Joy over Sadness, Anger and Fear when listening to the note A. This correlation could be explained by the fact that the A note is the standard tuning note on the guitar. 34 participants were musically proficient, with guitar as their choice instrument. Hearing this particular note could have contributed to elicit positive emotions, and it could be possible that other guitar players have an overall more positive emotion perception when hearing sounds from a guitar. It could be also similar to both the optimistic Joy and the conventional standard tuning note dimensions for the Conscientiousness trait mentioned above. While both musicians and non-musicians can have an understanding of communicating expressive content, as presented in Section 2.2.2, musicians use a greater amount of temporal fine structure TFS information and a higher emotional resolvability curve 27. This could impact how musicians respond to musical notes in different ways to non-musicians and why musical proficiency correlates to Joy with regard to the A note. Table 2 shows interesting correlations between the Note C and the Aural and Physical learning styles. Participants who chose Aural or Physical as their preferred learning style were around seven times more likely to chose Anger. Studies have shown that, when learning an instrument, aural learning was the main learning style, but participants also used more logical and practical approaches when learning new songs 17. For aural learners, with musical experience 87.5 of aural learners, this correlation between the C note and the Aural learning style could be due to frustration of not having the option to use more logical and practical learning styles to help them understand the musical note being elicited. Looking at the positive correlation between Anger and the Physical learning style for the note C, some interesting insights can be seen. The C note is the fourth highest frequency tested in this study and while overall we can see from Table 1 that Joy is the significant emotion, higher frequencies can also garner annoyance in some people. A study measuring noise annoyance levels in working environments has shown that higher frequencies had the highest annoyance rating with the lowest frequencies having the lowest annoyance rating 25. It is possible that the Anger associated with the Physical, as well as the Aural learning styles, comes from the higher frequency of the C note. 4 CONCLUSIONS In this paper, we presented an experiment on auditory-emotion associations, looking to reveal the emotional potential of an apparently-basic stimulus such as a single musical note and the impact of other variables such as, personality, gender, age and musical experience on this association. Through this approach, we were able to more clearly distinguish the combination of key factors accounting for associations between auditory stimuli and emotion. Results showed significance on basic associations in lower notes to sadness and higher notes to joy, with a positive correlation between the four highest notes and the emotion joy, and a positive correlation between three of the four lowest notes and the emotion, sadness. Results pertaining to the impact of individual variables on auditory-emotion associations showed significant results on six of the twelve musical notes. The independent variables of gender, aural and physical learning styles, musical proficiency, the Conscientiousness personality trait, age and sound sensitivity were found to be significant variables in six of the twelve single musical notes, thus potentially impacting the emotional response to the auditory stimuli. Some limitations of this experiment include, for example, the use of only one octave and the choice of instrument for auditory stimuli. One octave was used in this experiment, to reproduce the test setup from 31, with a larger test group. In the future, it would be beneficial to study auditory-emotion associations in a range of octaves, to understand if pitch height-emotion associations are the most dominant associations regarding single musical notes. Also, the use of a single instrument type is an important factor in associations between single musical notes and emotions. Each instrument has a different timbre which elicits different emotion characteristics. As mentioned in Section 3.6.1, it has been shown that the timbre of the guitar is highly rated for negative emotional characteristics, where a Piano is rated as neutral, and a vibraphone is highly rated for positive emotional characteristics 9. Changing the instrument that elicits auditory stimuli, by adopting a piano neutral emotional characteristics or using multiple instrument sounds, with different emotional characteristics is important for future studies and will help understand single musical note-emotion associations and the impact of timbre and multiple octaves have on the emotion response. The findings of the experiment presented in the paper can help towards the formulation of a new auditory-visual framework that uses understandings on emotion, personality and other variables in the development of more personalised human-computer interfaces. These findings can improve the design of programs such as SoundStrokes presented in 31, that can assist in sharpening our associations between our senses. Further research into the aforementioned auditory-visual framework could lead to the creation of applications using computer-generated cross-modal stimuli, e.g., synthesised audio-visual tutorials, to learn or improve skills. These applications could be used for a multitude of purposes, such as learning an instrument or to paint; and in exploring new creative ways of expression, e.g., writing a song with a paint brush as the instrument or painting a picture with a piano as your bush. Creativity should not be limited to one form of expression and understanding the intricacies of our senses, combined with emotion, personality traits and other variables, it can provided a platform for multi-modal expression using digital tools. ACKNOWLEDGMENTS This publication has emanated from research supported in part by a Grant from Science Foundation Ireland under Grant number 18CRT6222. REFERENCES Toni Antonucci, Hiroko Akiyama, and Keiko Takahashi. 2004. Attachment and Close Relationships across the Life Span. Attachment Human Development 6, 4 Dec. 2004, 353370. Filippo Bonini Baraldi, Giovanni De Poli, and Antonio Rodà. 2006. Communicating Expressive Intentions with a Single Piano Note. Journal of New Music Research 35, 3 Sept. 2006, 197210. Lisa Feldman Barrett. 1998. Discrete Emotions or Dimensions? The Role of Valence Focus and Arousal Focus. Cognition Emotion 12, 4 July 1998, 579599. Thomas Baumgartner, Michaela Esslen, and Lutz Jäncke. 2006. From Emotion Perception to Emotion Experience: Emotions Evoked by Pictures and Classical Music. International Journal of Psychophysiology 60, 1 April 2006, 3443. Kira S. Birditt and Karen L. Fingerman. 2005. Do We Get Better at Picking Our Battles? Age Group Differences in Descriptions of Behavioral Reactions to Interpersonal Tensions. The Journals of Gerontology Series B: Psychological Sciences and Social Sciences 60, 3 May 2005, P121P128. Roberto Bresin. 2004. Real-Time Visualization of Musical Expression.. In HUMAINE Workshop From Signals to Signs of Emotion and Vice Versa. Santorini, 5. Clair Cassiello-Robbins, Deepika Anand, Kibby McMahon, Rachel Guetta, Jacqueline Trumbull, Lisalynn Kelley, and M. Zachary Rosenthal. 2020. The Mediating Role of Emotion Regulation Within the Relationship Between Neuroticism and Misophonia: A Preliminary Investigation. Frontiers in Psychiatry 11 Aug. 2020, 847. Tomas Chamorro-Premuzic and Adrian Furnham. 2007. Personality and Music: Can Traits Explain How People Use Music in Everyday Life?British Journal of Psychology 98, 2 2007, 175185. Chuck-Jee Chau, Bin Wu, and Andrew Horner. 2015. The Emotional Characteristics and Timbre of Nonsustaining Instrument Sounds. Journal of the Audio Engineering Society 63, 4 April 2015, 228244. Oliver Collignon, Simon Girard, Frédéric Gosselin, Dave Saint-Amour, Franco Lepore, and Maryse Lassonde. 2010. Women Process Multisensory Emotion Expressions More Efficiently than Men. Neuropsychologia 48, 1 Jan. 2010, 220225. Caroline Curwen. 2018. Music-Colour Synaesthesia: Concept, Context and Qualia. Consciousness and Cognition 61 May 2018, 94106. Richard J Davidson, Klaus R Scherer, and H. Hill Goldsmith. 2009. Handbook of Affective Sciences. Oxford University Press, New York; Oxford. Colin G. DeYoung. 2010. Personality Neuroscience and the Biology of Traits: Personality Neuroscience. Social and Personality Psychology Compass 4, 12 Dec. 2010, 11651180. Snjeana Dobrota and Ina Rei Ercegovac. 2015. The Relationship between Music Preferences of Different Mode and Tempo and Personality Traits Implications for Music Pedagogy. Music Education Research 17, 2 April 2015, 234247. Ryan Donovan, Aoife Johnson, Aine deRoiste, and Ruairi O'Reilly. 2020. Quantifying the Links Between Personality Sub-Traits and the Basic Emotions. In Computational Science and Its Applications ICCSA 2020, Osvaldo Gervasi, Beniamino Murgante, Sanjay Misra, Chiara Garau, Ivan Blei, David Taniar, Bernady O. Apduhan, Ana Maria A.C. Rocha, Eufemia Tarantino, Carmelo Maria Torre, and Yeliz KaracaEds.. Vol. 12250. Springer International Publishing, Cham, 521537. Howard Gardner. 1993. Frames of Mind: The Theory of Multiple Intelligences 2nd ed ed.. Fontana Press, London. Lucy Green. 2012. Musical Learning Styles and Learning Strategies in the Instrumental Lesson: Some Emergent Findings from a Pilot Study. Psychology of Music 40, 1 Jan. 2012, 4265. Annaliese Micallef Grimaud, Tuomas Eerola, and Nick Collins. 2019. EmoteControl: A System for Live-Manipulation of Emotional Cues in Music. In Proceedings of the 14th International Audio Mostly Conference: A Journey in Sound. ACM, Nottingham United Kingdom, 111115. Julia C. Hailstone, Rohani Omar, Susie M. D. Henley, Chris Frost, Michael G. Kenward, and Jason D. Warren. 2009. It's Not What You Play, It's How You Play It: Timbre Affects Perception of Emotion in Music. Quarterly Journal of Experimental Psychology 62, 11 Nov. 2009, 21412155. Kate Hevner. 1936. Experimental Studies of the Elements of Expression in Music. The American Journal of Psychology 48, 2 April 1936, 246. Edyta Monika Hunter, Louise H. Phillips, and Sarah E. MacPherson. 2010. Effects of Age on Cross-Modal Emotion Perception.Psychology and Aging 25, 4 Dec. 2010, 779787. Carroll E. Izard, Deborah Z. Libero, Priscilla Putnam, and O. Maurice Haynes. 1993. Stability of Emotion Experiences and Their Relations to Traits of Personality.Journal of Personality and Social Psychology 64, 51993, 847860. Patrik N. Juslin. 2013. What Does Music Express? Basic Emotions and Beyond. Frontiers in Psychology 4 2013. Lena Lambrecht, Benjamin Kreifelts, and Dirk Wildgruber. 2014. Gender Differences in Emotion Recognition: Impact of Sensory Modality and Emotional Category. Cognition and Emotion 28, 3 April 2014, 452469. Ulf Landström, Elisabeth Åkerlund, Anders Kjellberg, and Maria Tesarz. 1995. Exposure Levels, Tonal Components, and Noise Annoyance in Working Environments. Environment International 21, 3 Jan. 1995, 265275. Lawrence E Marks. 2004. Cross-Modal Interactions in Speeded Classification. In The Handbook of Multisensory Processes, Gemma Calvert, Charles Spence, and Barry E. SteinEds.. MIT Press, Cambridge, Mass, 85105. Francis A. M. Manno, Raul R. Cruces, Condon Lau, and Fernando A. Barrios. 2019. Uncertain Emotion Discrimination Differences Between Musicians and Non-Musicians Is Determined by Fine Structure Association: Hilbert Transform Psychophysics. Frontiers in Neuroscience 13 Sept. 2019. Solange Mardaga and Michel Hansenne. 2009. Do Personality Traits Modulate the Effect of Emotional Visual Stimuli on Auditory Information Processing?Journal of Individual Differences 30, 1 Jan. 2009, 2834. Gail Martino and Lawrence E Marks. 2000. Cross-Modal Interaction between Vision and Touch: The Role of Synesthetic Correspondence. Perception 29, 6 June 2000, 745754. Vincenzo Moscato, Antonio Picariello, and Giancarlo Sperli. 2020. An Emotional Recommender System for Music. IEEE Intelligent Systems2020, 11. Patrick O'Toole, Donald Glowinski, and Maurizio Mancini. 2019. Understanding Chromaesthesia by Strengthening Auditory-Visual-Emotional Associations. In 2019 8th International Conference on Affective Computing and Intelligent Interaction ACII. IEEE, Cambridge, United Kingdom, 17. Stephen E. Palmer, Karen B. Schloss, Zoe Xu, and Lilia R. Prado-Leon. 2013. Music-Color Associations Are Mediated by Emotion. Proceedings of the National Academy of Sciences 110, 22 May 2013, 88368841. Rosalind W Picard. 1997. Affective Computing. MIT Press, Cambridge, Mass. Beatrice Rammstedt and Oliver P. John. 2007. Measuring Personality in One Minute or Less: A 10-Item Short Version of the Big Five Inventory in English and German. Journal of Research in Personality 41, 1 Feb. 2007, 203212. Ted Ruffman, Julie D. Henry, Vicki Livingstone, and Louise H. Phillips. 2008. A Meta-Analytic Review of Emotion Recognition and Aging: Implications for Neuropsychological Models of Aging. Neuroscience Biobehavioral Reviews 32, 4 Jan. 2008, 863881. Charles Spence. 2011. Crossmodal Correspondences: A Tutorial Review. Attention, Perception, Psychophysics 73, 4 May 2011, 971995. Charles Spence. 2020. Assessing the Role of Emotional Mediation in Explaining Crossmodal Correspondences Involving Musical Stimuli. Multisensory Research 33, 1 July 2020, 129. Xiuwen Sun, Xiaoling Li, Lingyu Ji, Feng Han, Huifen Wang, Yang Liu, Yao Chen, Zhiyuan Lou, and Zhuoyun Li. 2018. An Extended Research of Crossmodal Correspondence between Color and Sound in Psychology and Cognitive Ergonomics. PeerJ 6 March 2018, e4443. Tawney Tsang and Karen B. Schloss. 2010. Associations between Color and Music Are Mediated by Emotion and Influenced by Tempo: 525772013-006. Jonna K. Vuoskoski and Tuomas Eerola. 2011. Measuring Music-Induced Emotion: A Comparison of Emotion Models, Personality Biases, and Intensity of Experiences. Musicae Scientiae 15, 2 July 2011, 159173. Teija Waaramaa. 2017. Gender Differences in Identifying Emotions from Auditory and Visual Stimuli. Logopedics Phoniatrics Vocology 42, 4 Oct. 2017, 160166. J Ward, B Huckstep, and E Tsakanikos. 2006. Sound-Colour Synaesthesia: To What Extent Does It Use Cross-Modal Mechanisms Common to Us All?Cortex 42, 2 2006, 264280. Kelly L. Whiteford, Karen B. Schloss, Nathaniel E. Helwig, and Stephen E. Palmer. 2018. Color, Music, and Emotion: Bach to the Blues. i-Perception 9, 6 Nov. 2018, 204166951880853. Lee H. Wurm, Gisela Labouvie-Vief, Joanna Aycock, Kristine A. Rebucal, and Heather E. Koch. 2004. Performance in Auditory and Visual Emotional Stroop Tasks: A Comparison of Older and Younger Adults.Psychology and Aging 19, 3 2004, 523535. Marcel Zentner, Didier Grandjean, and Klaus R. Scherer. 2008. Emotions Evoked by the Sound of Music: Characterization, Classification, and Measurement.Emotion 8, 4 2008, 494521. Zhihong Zeng, M. Pantic, G.I. Roisman, and T.S. Huang. 2009. A Survey of Affect Recognition Methods: Audio, Visual, and Spontaneous Expressions. IEEE Transactions on Pattern Analysis and Machine Intelligence 31, 1 Jan. 2009, 3958. FOOTNOTE 1 This work is licensed under a Creative Commons Attribution International 4.0 License. ICMI '21 Companion, October 1822, 2021, Montréal, QC, Canada 2021 Copyright held by the ownerauthors. ACM ISBN 978-1-4503-8471-12110.DOI:\",\n",
       " 'https://www.unprofesor.com/musica/tipos-de-cadencia-musical-3912.html?utm_source=chatgpt.com#anchor_1': 'Todos los TIPOS de CADENCIA musical - RESUMEN CORTO!! Descubre Matemáticas Lengua española Ciencias Sociales Ciencias Naturales Música Física Química Inglés Tecnología e Informática Consejos para estudiar COMPARTIR Buscar unPROFESOR Música Lenguaje musical Los sonidos Tipos de cadencia musical Los sonidos Tipos de cadencia musical Valoración: 4 4 votos 4 comentarios Por Ana Sofía Rivera. 21 enero 2020 Lección anteriorPolifonia musical: características y... Lección siguienteQué es el contrapunto en música Una de las cualidades innegables en el arte es la capacidad de crear un discurso, un a serie de ideas que están entrelazadas entre sí para poder expresar un sentimiento concreto. Gracias a la estructura y las formas del arte como método de comunicación, podemos establecer una forma elegante de hacer llegar nuestro mensaje de la manera mas sensible posible.La música es uno de esos artes que nos permite hacer entender a nivel sentimental, esto en gran parte lo debemos a la forma tan refinada que tiene de llevarnos casi inconscientemente a la comprensión, de manera casi misteriosa por medio de la sucesión de sonidos. En esta lección de unPROFESOR hablaremos acerca de un componente de la música que nos permite lograr esto: los tipos de cadencia musical. También te puede interesar: Tipos de textura musical Índice Qué es una cadencia musical Los grados de la tonalidad en la música Los diferentes tipos de cadencia que existen Qué es una cadencia musical La música posee el elemento del tiempo, es decir que no es algo estático sino todo lo contrario, va cambiando mientras transcurre y es esto lo que le hace tener tanta vida. Otro factor crucial en la música es la dinámica que causa en cuanto a percepción de tensión y resolución, es decir que auditivamente tenemos la sensación de que cuando algo es muy denso, debe soltar esa tensión eventualmente. Es esta liberación lo que nos resulta tan placentero en la música y lo que hace que pueda transcurrir en el tiempo, tener ciclos, evolución y así crear un discurso.La palabra cadencia viene del italiano y significa caer. Con esta palabra nos referimos a la necesidad de resolución antes mencionada. La estructura de una obra o canción musical se construye por una serie de acordes en un orden determinado. Si bien este orden queda a la merced del compositor, no es una sucesión aleatoria, ya que se rige por las reglas armónicas que le dan sentido a la música.Toda progresión de acordes debe terminar eventualmente, desembocar en algún sitio y es precisamente a la acción de resolver a lo que le llamamos cadencia, es el momento y acorde en la música en la que un acorde cae. Imagen: Pinterest Los grados de la tonalidad en la música Antes de conocer los tipos de cadencia debemos tener muy claro el concepto de los grados de la tonalidad y por supuesto, de tonalidad en sí.En resumen, la tonalidad son las reglas que nos dictan el contexto armónico, las notas que podemos utilizar en una composición. Gracias a estas reglas logramos saber que tipos de acordes podemos utilizar y con esto, establecemos los grados de la tonalidad.Los grados de la tonalidad se encuentran en la escala base que estamos utilizando ejemplo: escala mayor, escala menor, escala dórica... etc. En una escala estándar tenemos 7 notas, y por lo tanto obtenemos 7 grados. Cada uno de los grados posee un nombre específico según su función, que esta definido por la cantidad de tensión o sensación de resolución. Estos son los nombres de los grados de tonalidad:I Primer grado: tónica fundamentalII Segundo grado: supertónicaIII Tercer grado: medianteIV Cuarto grado: subdominanteV Quinto grado: dominanteVI Sexto grado: superdominante o submedianteVII Séptimo grado: sensibleEl grado de resolución por excelencia es el primer grado, tónica o fundamental, ya que nos provee la mayor sensación de conclusión gracias a su estabilidad armónica. Imagen: Slideshare Los diferentes tipos de cadencia que existen Existen muchos tipos de cadencia ya que la música es un arte y depende de la creatividad. Sin embargo en el transcurso de la historia se han utilizado con frecuencia ciertas cadencias gracias a su conocida funcionalidad. Existen dos categorías para las cadencias: cadencias conclusivas y cadencias suspensivas.Las cadencias conclusivas son aquellas que alcanzan una resolución y por lo tanto una finalización clara. Por el contrario, una cadencia suspensiva es aquella que no brinda una resolución y que provoca la sensación de que el sonido debe continuar.Para ambos tipos de cadencia existen algunos tipos estándar.Cadencias conclusivasCadencia perfecta: Va directamente de la dominante V a la tónica I.Cadencia imperfecta: Va de la dominantes V a la tónica I pero la organización de las notas se encuentra invertido o la voz más aguda no resuelve al primer grado.Cadencia plagal: Va de la subdominante IV a la tónica I.Cadencia compuesta: Sucesión subdominante IV - dominante V - tónica I.Cadencia preclásica: Sucesión subdominante IV - dominante V dominante octavada y tónica I.Cadencias suspensivasSemicadencia: Cuando se da un reposo en la subdominante IV o dominante V, pero no resuelve aún.Cadencia imperfecta: cuando en una cadencia perfecta el acorde de tónica se produce en un tiempo débil o si alguno de sus acordes se encuentra invertido cuando la nota fundamental del acorde no es la más grave.Cadencia rota o deceptiva: cuando una cadencia da la sensación de que resolverá a la tónica pero en cambio ese acorde es sustituido por un grado no resolutivo.Con estos conocimientos de la cadencias ya tienes un acercamiento para las bases de la música y de su composición. La música se compone de muchas relaciones que debemos ir estudiando poco a poco, para poder expresarnos en el arte con propiedad. Imagen: Musicnet Si deseas leer más artículos parecidos a Tipos de cadencia musical, te recomendamos que entres en nuestra categoría de Lenguaje musical. Lección anteriorPolifonia musical: características y... Lección siguienteQué es el contrapunto en música Categorías relacionadas Instrumentos musicalesHistoria de la Música Lo más visto 1.Cuáles son las notas musicales en el pentagrama2.Etapas de la música3.Nombres de los instrumentos de cuerda4.Principales elementos de la música5.Notas musicales: símbolos y nombres6.Música en la Prehistoria: resumen7.Figuras musicales y su duración8.Instrumentos de viento madera Más lecciones de Los sonidos Lección 5 de 14 Qué es la forma musical y sus clasificaciones Lección 6 de 14 Estructura de la forma sonata Lección 7 de 14 Tipos de melodías y sus características Lección 8 de 14 Polifonia musical: características y ejemplos Lección 9 de 14 Tipos de cadencia musical Lección 10 de 14 Qué es el contrapunto en música Lección 11 de 14 Contrapunto musical: ejemplos Lección 12 de 14 Canon musical: definición y ejemplos Quiero ver más lecciones! Pregunta al profesor sobre Tipos de cadencia musical Tu valoración: Qué te ha parecido el artículo? Enviar comentario He leído y acepto la política de privacidad Red Link To Media recopila los datos personales solo para uso interno. En ningún caso, tus datos serán transferidos a terceros sin tu autorización.De acuerdo con la ley del 8 de diciembre de 1992, puedes acceder a la base de datos que contiene tus datos personales y modificar esta información en cualquier momento, poniéndote en contacto con Red Link To Media SL infolinktomedia.net 4 comentarios Su valoración: Roberto 23092024 Y cómo se llamarían las cadencias que provienen de cualquier otro grado, que no sean ni el IV o V, hacia un I? Responder 0 0 Su valoración: Pedro 26012024 y si tengo una cadencia III - I , como se le llamaría? Responder 0 0 Su valoración: Claudia Velazco 28022023 Ejemplos de canciones que tengan cadencia perfecta y plagal? Responder 0 1 Su valoración: Basilio 21062021 C - A - D - G7 I - VI - II - V Que clase de cadencia es esta? Ver 2 respuestas Responder 0 2 Ricardo Fernández-Lestón 18032022 Yo diría que es una cadencia suspensiva imperfecta. 0 0 Cesar 25092023 En el jazz esa cadencia se conoce como Turn Around 0 0 Tipos de cadencia musical Imagen: Pinterest Imagen: Slideshare Imagen: Musicnet 1 de 4 Tipos de cadencia musical Volver arriba Redes sociales Aprender matemáticas Aprender lengua española Aprender ciencias sociales Aprender ciencias naturales Aprender música Aprender física Aprender química Aprender inglés Aprender tecnología e informática Consejos para estudiar unprofesor.com 2025 Quiénes somos Contacta con nosotros Términos y Condiciones Política de privacidad Política de cookies Compartir en:',\n",
       " 'https://eldiaadiariomusica.wordpress.com/2013/06/23/sentido-y-personalidad-de-las-tonalidades/': \"Sentido y personalidad de las Tonalidades Música que siento Música que siento Ir al contenido Un rincón literario Artículos Montserrat Figueras y el Cant de la Sibilla Tonalidad de Si bemol menor Sentido y personalidad de las Tonalidades Publicado el 23 de junio de 2013 por Manel Artero Hubo un tiempo en el que se aceptaba otorgar una cierta personalidad a cada una de las tonalidades que pueden construirse con el sistema de afinación temperada, establecido desde el barroco y hasta la ruptura que supuso la nueva Armonía que estableció Arnold Schöenberg. Ese concepto de personalidad debió tener su apogeo en el Romanticismo, decayendo a finales del siglo XIX y principios del XX. No hay nadie, al menos yo no lo he encontrado, que haya demostrado en la práctica que esa convención es cierta. A pesar de ello sí que podemos encontrarnos con tonalidades que nos transmites distintas sensaciones. Pero también es cierto que eso puede atribuirse a la calidad de la melodía de los temas, a su orquestación, a su armonización e incluso al modo de utilizar la mezcla de timbres de los distintos instrumentos. A pesar de ello comparto con vosotros una tabla con lo que se petende que transmite cada tonalidad. A partir de ésta entrada intentaré publicar una obra que esté escrita en cada una de ellas para que podamos juzgarlo entre todos. Tonalidades Mayores Tonalidad Personalidad Do mayor Alegre, guerrero, completamente puro. Su carácter es de inocencia y de simplicidad. Do sostenido mayor Miradas lascivas. Pena y éxtasis. No puede reír, pero puede sonreír. No puede aullar, sólo puede hacer una mueca de su llanto. Caracteres y sentimientos inusuales. Re mayor Feliz y muy guerrero. El triunfo, Aleluyas, júbilo, victoria. Mi bemol mayor Crueldad, dureza, amor, devoción, conversación íntima con Dios. Mi mayor Querellante, chillón, gritos ruidosos de alegría, placer al reírse. Fa mayor Furioso y arrebatado. Fa sostenido mayor Triunfo sobre la dificultad, libertad, alivio, superación de obstáculos, el eco de un alma que ferozmente ha lidiado y finalmente conquistó. Sol mayor Dulcemente jovial, idílico, lírico, calmado, pasión satisfecha, gratitud por la amistad verdadera y el amor esperanzado, emociones gentiles y pacíficas. La bemol mayor Gravedad, muerte y putrefacción. La mayor Alegre, campestre, declaración de amor inocente, satisfacción, la esperanza de volver lo que le pertenece a uno de nuevo al regresar de una partida, juventud, aplausos y creencia en Dios. Si bemol mayor Magnífico, alegría, amor alegre, conciencia limpia, metas y deseos por un mundo mejor. Si mayor Duro, doliente, deslumbrante, fuertemente coloreado, anunciando pasiones salvajes, enfado, odios y resentimientos. Tonalidades menores Tonalidad Personalidad Do menor Oscuro y triste. Declaración de amor y a la vez lamento de un amor no correspondido. Anhelos y suspiros. Do sostenido menor Sentimientos de ansiedad, angustia y dolor profundo en el alma, desesperación, depresión, sentimientos sombríos, miedos, indecisiones, escalofríos. Si los fantasmas hablaran se aproximarían a esta tonalidad. Re menor Grave y devoto. Melancolía femenina. El rencor. Mi bemol menor Horrible, espantoso. Mi menor Afeminado, amoroso, melancólico. Fa menor Oscuro, doliente, depresivo, lamento funerario, gemidos de miseria, nostalgia solemne. Fa sostenido menor Pesimista, triste, sombrío, oscuro, terco a la pasión, resentimientos, descontentos. Sol menor Serio, magnífico, descontento, preocupado por el rompimiento de los esquemas, mal templado, rechinamiento de dientes, disgusto. La bemolmenor Quejándose todo el tiempo, incomplaciente, insatisfecho, corazón sofocado, lamentos, dificultades. La menor Tierno, lloroso, piedad femenina. Si bemol menor Oscuro, terrible, criatura pintoresca y curiosa, ropa de noche, tosco, maleducado, burlesco, descortés, descontento con sí mismo, sonidos del suicidio. Si menor Solitario, melancólico, ermitaño, paciencia, fe y sumisión esperando el perdón divino. Tu voto:Comparte esto:Haz clic para compartir en Twitter Se abre en una ventana nuevaHaz clic para compartir en Facebook Se abre en una ventana nuevaHaz clic para compartir en Tumblr Se abre en una ventana nuevaHaz clic para compartir en Pinterest Se abre en una ventana nuevaHaz clic para compartir en LinkedIn Se abre en una ventana nuevaHaz clic para compartir en WhatsApp Se abre en una ventana nuevaHaz clic para enviar un enlace por correo electrónico a un amigo Se abre en una ventana nuevaHaz clic para imprimir Se abre en una ventana nuevaMe gusta Cargando... Relacionado Acerca de Manel Artero Manel Artero, nacido en Barcelona, en el barrio de Poble Sec, dedicó gran parte de su vida a la informática, compaginando con ella su amor por la lectura y por la música. De esta última cursó un grado de Historia. Más tarde haría los tres cursos de narrativa y novela de lEscola descriptura de lAteneu barcelonès que le abriría las puertas al mundo de la escritura del que siempre formó parte sin saberlo. Desde entonces ganado diversos premios en concursos de relatos. El más sobresaliente, el de la Asociación El coloquio de los perros de Córdoba. Compagina su tiempo entre la escritura y diversos talleres y charlas sobre música, lectura y cultura de paz, que imparte en Cerdanyola del Vallès. El ladrón de rostros es su primera novela. Editada originalmente en 2017 por la editorial Maluma y6 reeditada por su hijo, Roger Artero, en 2023. Ver todas las entradas por Manel Artero Esta entrada fue publicada en Tonalidad y etiquetada afinación, personalidad, tonalidad. Guarda el enlace permanente. Montserrat Figueras y el Cant de la Sibilla Tonalidad de Si bemol menor 26 respuestas a Sentido y personalidad de las Tonalidades Pingback: Tonalidad de Si bemol menor Pingback: Sentido de las tonalidades. Hoy: Do Mayor Música que siento Roberto Reffray dijo: 30 de marzo de 2016 en 16:48 Hola. Estoy haciendo mi tesis de pregrado de la traducción del Dichterliebe de Schumann para ser interpretado. Ahora, me pareció muy interesante la relación que existe entre tonalidad y personalidad. Puedes decirme la fuente, por favor? Gracias. Responder Agustí dijo: 23 de octubre de 2023 en 15:04 Hola, existe un libro de un talChristian Friedrich Daniel Schubart que hizo un estudio sobre el tema allá por el año 1806 y que se llama deen zu einer Ästhetik der Tonkunst, que viene a decir Ideas para una estética del arte musical. Sólo lo he visto en catalán bajo el título Idees per a una estètica de lart musical pero aún no he conseguido encontrarlo en las librerias. Si alguien tiene más suerte que yo ya lo comentareis. Saludos a tods. Responder Manel Artero dijo: 25 de octubre de 2023 en 5:44 Muchísimas gracias por tu aportación. Recibe un cordial saludo. Roberto Reffray dijo: 30 de marzo de 2016 en 16:59 Hola. Estoy haciendo una tesis de pregrado sobre la traducción del Dichterliebe de Schumann, para ser interpretada al español. Me parece muy interesante la relación que existe entre las tonalidades y la personalidad que cada armadura transmite, podrías decirme la fuente, por favor? Gracias. Responder Manel Artero dijo: 30 de marzo de 2016 en 22:30 Hola Roberto, Lo cierto es que la fuente no es demasiado rebuscada. Copié directamente la tabla que ofrece la Wikipedia: Pero creo recordar que la comparé con algún otro lugar y eran muy parecidas. No pensé en contrastarla con ninguno de los libros que tengo de música. No sé si te habrá servido. Un saludo Responder Rafael dijo: 3 de octubre de 2019 en 0:52 Hola. Me identifico un poco con como las veo yo. No venía buscando algo científico u objetivo sino la experiencia de una persona. Me interesa conocer lo que se dice de las tonalidades para ver si coincidimos en sensaciones las personas que les buscamos un significado a las tonalidades. Añadiría,bajo mi punto de vista: Re Mayor: el cielo, visto como algo espiritual. Mi bemol Mayor: calor maternal, una madre. Mi Mayor: Humanidad. Unión humana. Fa Mayor: Juventud, pasión aventurera. La persona joven que se lanza a hacer algo con mucho corazón pero poco conocimiento por no haber vivido suficiente. Amor romántico. El no importar qué pasará mañana. Sol Mayor: el mar, profundidad, misterio, paz, inspiración, arte, romanticismo en el sentido artístico La Mayor: aire, viento, algo ligero, claro en sentido de color y despreocupado, libertad. Si bemol Mayor: la tonalidad usual de los brindis. Celebración. Si Mayor: intranquilidad. Re menor: el destino. La fuerza natural de la realidad. Mi menor: melancolía, nostalgia, el llanto que sana. Profundidad. Fuerza. Sol menor: rabia, batalla. La menor: delicadeza, canción de amor, lamento. Responder Manel Artero dijo: 3 de octubre de 2019 en 12:34 Hola Rafael, ante todo gracias por tu comentario. En mi caso, todo y que vivo para el sonido desde bastante joven, no tengo una percepción tan afinada como la tuya. Imagino que son niveles de sensibilidad o de interés. En cambio me identifico con los timbres y las disonancias. Ellos sí me transportan a otro estado de percepción. Te felicito por tanta sensibilidad. Recibe un cordial saludo. Responder María Hornos Miller dijo: 16 de abril de 2020 en 3:57 El Preludio de Rigoletto, de Verdi, está escrito en la tonalidad de do menor y es tal como tú lo describes: tragedia, desesperación, certeza de que todo se hará pedazos. Gracias por tu artículo. Responder Manel Artero dijo: 16 de abril de 2020 en 12:43 Gracias a ti por pasar por el blog y leerlo. Saludos cordiales. Responder Pingback: Download Mp3 COMO ESCRIBIR UNA CANCIÓN. PARTE 1. LOS MODOS Songs carlos dijo: 31 de octubre de 2020 en 15:05 Muy interesante, llevo ya cuatro años trasteando con FL Studio que no solo sirve para hacer trap y bastantes sintetizadores virtuales y aprendiendo un poco sobre música, escalas y demás; sé que no alcanzaré nunca alguien que la ha estudiado de verdad pero componer aunque sea modestamente me llena de verdad. Ahora gracias a este Post estoy experimentando con los 24 modos entre mayor y menor de una manera consciente y tengo que decir que sí que suenan esos matices que se apuntan y sabiéndolo, trato de buscar esos adjetivos y el resultado es más potente. Estaría bien un post con otros modos tipo Frigio, eólico e incluso de otras culturas como la india que tienen matices diferentes si se trasladan a la sonoridad occidental un saludo. Responder carlos dijo: 31 de octubre de 2020 en 15:09 Muy interesante, llevo ya cuatro años trasteando con FL Studio y bastantes sintetizadores virtuales y aprendiendo un poco sobre música, escalas y demás; sé que no alcanzaré nunca alguien que la ha estudiado de verdad pero componer aunque sea modestamente me llena de verdad. Ahora gracias a este Post estoy experimentando con los 24 modos entre mayor y menor de una manera consciente y tengo que decir que sí que suenan esos matices que se apuntan y sabiéndolo, trato de buscar esos adjetivos y el resultado es más potente. Ahora gracias a este Post estoy experimentando con los 24 modos entre mayor y menor de una manera consciente y tengo que decir que sí que suenan esos matices que se apuntan y sabiéndolo, trato de buscar esos adjetivos y el resultado es más potente. Estaría bien un post con otros modos tipo Frigio, eólico e incluso de otras culturas como la india que tienen matices diferentes si se trasladan a la sonoridad occidental un saludo. Responder Manel Artero dijo: 31 de octubre de 2020 en 17:29 Hola Carlos, Ante todo gracias por tu aportación. Sí que me encantaría entrar en la complejidad de la música india. Su división de la octava es más compleja, sus ritmos también Pero me falta tiempo. Me es imposible dedicarle al blog todo el tiempo que desearía. No obstante tomo nota. En cuanto a las escalas y modos griegos puedo asegurarte que en Youtube hay muchísmas cosas. Un saludo. Responder Manel Artero dijo: 31 de octubre de 2020 en 17:31 Olvidé decirte que me alegra muchísimo que el Post te haya servido para experimentar con los modos. Responder carlosgecheverria dijo: 31 de octubre de 2020 en 19:30 Sí, muchas gracias. Aún sigo con ello. Saludos Estaba de paso dijo: 31 de octubre de 2020 en 22:03 No tengo mucha idea de música, pero me parece una manera muy buena de aprender música con la ayuda de las emociones. Es importante darle un sentido al solfeo.Muy interesante gracias! Responder Manel Artero dijo: 31 de octubre de 2020 en 22:32 Gracias a ti por pasarte a leerme. Un saludo. Responder Elide dijo: 7 de junio de 2021 en 20:43 Tonalidad de Fa M, totalmente queda con el Va Pensiero! de Nabbuco de Verdi Responder Paula dijo: 22 de marzo de 2023 en 10:44 Buenos días, Me preguntaba cuál es la personalidad de re bemol mayor. No aparece en tu tabla ni en wikipedia, me parece extraño. Atentamente, Responder Manel Artero dijo: 3 de abril de 2023 en 13:51 Hola Paula, encantado de encontrarte por aquí. Preguntas por una de las tonalidades que no pude encontrar en su momento. No sé si puede servirte, pero buscando he encontrado esto: Antes de finales del siglo XIX, se afinaba con temperamentos distintos o sea, cada tonalidad sonaba ligeramente distinta. Por lo tanto, cada tonalidad tenía asociada unas cualidades. Re bemol mayor, la que trajo tu comentario, era la una tonalidad lasciva que degenera en pena y arrebato. Hector Berlioz llamó a esta tonalidad majestuosa en su Gran Tratado de Instrumentación5 mientas que a su tonalidad enarmónica, do sostenido mayor, la definió como menos imprecisa que do mayor y más elegante que esta. Espero que te sirva. Recibe un cordial saludo. Responder Vanessa dijo: 31 de marzo de 2023 en 18:01 Hola a todos, alguien sabe las emociones que emite Sol sostenido menor? Muchas gracias. Responder Manel Artero dijo: 1 de abril de 2023 en 23:40 Hola Vanessa, he buscado pero no la encuentro. De todos modos, su equivalente sonoro sería la de La bemol menor ya que Sol sostenido es la nota enarmónica suena igual que el La bemol. Espero que pueda servirte. Recibe un cordial saludo. Responder Noa Ayra Yishay dijo: 17 de julio de 2024 en 9:53 Hola! Tiene algun nombre en concreto esta teoria?? Gracias Responder Manel Artero dijo: 18 de julio de 2024 en 10:54 Hola, Noa, Ante todo decirte que las definiciones y asociaciones que se hacen con ellas son meramente subjetivas. Dicho esto, se las conoce generalmente como características afectivas de las tonalidades o afectos de las tonalidades. Aunque no tiene un nombre específico universalmente aceptado. Recibe un cordial saludo. Responder Deja un comentario Cancelar la respuesta Buscar: Ejemplo de audio del libro Ir a descargar Y a escuchar todo el Podcast Suscríbete al Blog Enter your email address to follow this blog and receive notifications of new posts by email. Dirección de correo electrónico: Suscripción Únete a otros 269 suscriptores Anécdotas Ars Antiqua Bach banda sonora Barroco Belleza canción concierto De Otros Grecia Historia de la música jazz Jordi Savall king Crimson mozart Novela Pasion perfeccion poesía Robert Fripp Rock Progresivo sencillez sensibilidad sensualidad Sinfonía Tonalidad tristeza trovadores Uncategorized wagner Archivos Archivos Elegir el mes enero 2025 septiembre 2024 junio 2024 noviembre 2023 octubre 2023 agosto 2023 julio 2023 May 2023 abril 2023 marzo 2022 noviembre 2021 marzo 2021 febrero 2021 octubre 2020 septiembre 2020 junio 2020 May 2020 abril 2020 noviembre 2019 agosto 2019 julio 2019 junio 2019 abril 2019 marzo 2019 enero 2019 diciembre 2018 noviembre 2018 agosto 2018 abril 2018 marzo 2018 febrero 2018 enero 2018 diciembre 2017 noviembre 2017 octubre 2017 septiembre 2017 agosto 2017 julio 2017 junio 2017 abril 2017 marzo 2017 diciembre 2016 noviembre 2016 octubre 2016 julio 2016 junio 2016 May 2016 abril 2016 marzo 2016 febrero 2016 enero 2016 diciembre 2015 noviembre 2015 octubre 2015 agosto 2015 junio 2015 May 2015 abril 2015 marzo 2015 febrero 2015 enero 2015 diciembre 2014 noviembre 2014 octubre 2014 agosto 2014 junio 2014 May 2014 abril 2014 marzo 2014 febrero 2014 diciembre 2013 noviembre 2013 octubre 2013 septiembre 2013 agosto 2013 julio 2013 junio 2013 May 2013 abril 2013 marzo 2013 enero 2013 diciembre 2012 noviembre 2012 octubre 2012 septiembre 2012 agosto 2012 julio 2012 junio 2012 Blogroll Ancha es mi casa Aula de Música Azul, el principio fue azul Bach tras Bach Bachiano Belleza sin palabras Camino de música Conciertos en el Delibes EL cavaller del Cigne Generador de Frecuencias sonoras Historia de la Música La mejor guitarra La vuelta al mundo en 80 músicas Música antigua música con nocturnidad y alevosía Música y literatura en clave personal Melomanía y otros estados sensoriales Radio Kras Tarab Al Andalus Tono menor, un blog de clásica Voces para la Paz El Día a Diario Música by Manel Artero Badenes is licensed under a Creative Commons Reconocimiento-SinObraDerivada 3.0 Unported License.Permissions beyond the scope of this license may be available at Meta Registro Iniciar sesión Feed de entradas Feed de comentarios WordPress.com Enlaces RSS RSS - Comentarios Comptador functioni,s,o,g,r,a,mi'GoogleAnalyticsObject'r;irirfunction ir.qir.q.pusharguments,ir.l1new Date;as.createElemento, ms.getElementsByTagNameo0;a.async1;a.srcg;m.parentNode.insertBeforea,m window,document,'script',' ga'create', 'UA-50423519-1', 'wordpress.com'; ga'send', 'pageview'; está Dísticas? 121.601 hits document.writeunescape3Cscript src27 type27textjavascript273E3Cscript3E; try Histats.start1,1967963,4,107,170,20,00001010; Histats.framedpage; Histats.trackhits; catcherr; Música que siento Web construida con WordPress.com. Comentar Rebloguear Suscribirse Suscrito Música que siento Únete a otros 46 suscriptores Suscríbeme Ya tienes una cuenta de WordPress.com? Inicia sesión. Privacidad Música que siento Personalizar Suscribirse Suscrito Regístrate Iniciar sesión Copiar enlace corto Denunciar este contenido View post in Reader Gestionar las suscripciones Contraer esta barra d Diseña un sitio como este con WordPress.comComenzar\"}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_database = {}\n",
    "for key, value in database.items():\n",
    "    clean_database[key] = preprocess_text(value)\n",
    "\n",
    "clean_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  removed the ones for which we were unable to extract information\n",
    "del clean_database['https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3779798/']\n",
    "del clean_database['https://www.psypost.org/new-research-uncovers-atonal-musics-distinct-emotional-and-neural-effects/']\n",
    "del clean_database['https://online.ucpress.edu/mp/article/40/3/202/195230/The-Perceptual-and-Emotional-Consequences-of']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['https://www.kennedy-center.org/education/resources-for-educators/classroom-resources/media-and-interactives/media/music/your-brain-on-music/your-brain-on-music/your-brain-on-music-tearjerkers/', 'https://dl.acm.org/doi/fullHtml/10.1145/3461615.3485419', 'https://www.unprofesor.com/musica/tipos-de-cadencia-musical-3912.html?utm_source=chatgpt.com#anchor_1', 'https://eldiaadiariomusica.wordpress.com/2013/06/23/sentido-y-personalidad-de-las-tonalidades/'])\n"
     ]
    }
   ],
   "source": [
    "print(clean_database.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/clean_knowledge_base.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(clean_database, file, ensure_ascii=False, indent=4)\n",
    "# lo guardamo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vamos a checkear que tal funciona nuestra api para obtener las features necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# loading the craft knowledge database \n",
    "with open(\"data/clean_knowledge_base.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "with open('data/music_modes.json', 'r', encoding=\"utf-8\") as f:\n",
    "    modes = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today I feel a bit strange, like one of those days when everything is fine but something feels out of place. I am calm, but there is this sense that I could be doing more or feeling more. It's like being on pause, not sad, but not entirely joyful either. I suppose it would be something soft and calm, with a touch of introspection.\n"
     ]
    }
   ],
   "source": [
    "user_text = \"\"\"\n",
    "Today I feel a bit strange, like one of those days when everything is fine but something feels out of place. \n",
    "I am calm, but there is this sense that I could be doing more or feeling more. \n",
    "It's like being on pause, not sad, but not entirely joyful either. \n",
    "I suppose it would be something soft and calm, with a touch of introspection.\n",
    "\"\"\"\n",
    "\n",
    "clean_user_text = preprocess_text(user_text)\n",
    "print(clean_user_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_base = (\n",
    "    \"You are an expert in music and a psychologist specializing in the relationship between music and emotions. \"\n",
    "    \"Your task is to analyze the text provided by a user, understand the underlying emotional state, and translate it into specific musical characteristics.\\n\\n\"\n",
    "    \"You must return a dict with the following structure, feature_name:  feature_value_given.\\n\\n\"\n",
    "    \"A SPECIFIC VALUE FOR EACH FEATURE MUST BE GIVEN AS A USEFUL VALUE\\n\\n\"\n",
    "    \"If user includes a specific tonality, construct the cadence in orden to satisfy its request\\n\\n\"\n",
    "    \"Extract the following musical features, justifying below the feature dict your choices based on the text:\\n\\n\"\n",
    "    \"1. Tempo: The speed of the music (fast or slow) and how it relates to the described emotional energy.\\n\"\n",
    "    \"2. Intensity/Dynamics: Volume (crescendos, diminuendos) and its connection to perceived tension or calm.\\n\"\n",
    "    \"3. Timbre: The quality of sound (dark or bright) and its influence on the emotional atmosphere.\\n\"\n",
    "    \"4. Rhythm: Rhythmic pattern (regular or irregular) and how it evokes stability or emotional unease.\\n\"\n",
    "    \"5. Harmonic progression: Provide an exact chord progression (e.g., C-G-Am-F or I, IV, V, I) that reflects the emotional state.\\n\"\n",
    "    \"6. Melody: Direction and shape (ascending or descending) and how it reflects joy, sadness, or other emotions.\\n\"\n",
    "    \"7. Tonality/Mode: Key and mode (major, minor, dorian, etc.) and its influence on the emotional color of the text.\\n\"\n",
    "    \"8. Articulation: Playing style (staccato, legato, etc.) and its relationship to the expressiveness described.\\n\"\n",
    "    \"9. Silence: Use of pauses or silences between notes to evoke introspection, suspense, or tranquility.\\n\\n\"\n",
    "    \"After the characteristics, develop a sequence of musical notes (C, A, Eb, ...) in the form of a melody in accordance with the tonality of the cadence you have chosen.\"\n",
    "    \"Additionally, use the provided additional data to enrich your analysis and relate musical characteristics to relevant information. \"\n",
    "    \"Combine your skills in music and emotional psychology to provide a detailed and precise response.\\n\\n\"\n",
    "    \"User's text:\\n{user_text}\\n\\n\"\n",
    "    \"Additional data:\\n{additional_data}, {muical_modes}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"one - Tone - Semitone - Tone - Tone - Tone - Semitone', 'sonority': 'Bright, stable, cheerful.', 'ex\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "musical_modes = \"\\n\".join([f\"- {key}: {value}\" for key, value in modes.items()])\n",
    "musical_modes[50:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eractives/media/music/your-brain-on-music/your-brain-on-music/your-brain-on-music-tearjerkers/: Your'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knw_data = \"\\n\".join([f\"- {key}: {value}\" for key, value in data.items()])\n",
    "knw_data[100:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = knw_data + \"\\n\" + musical_modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r emotional unease.\\n5. Harmonic progression: Provide an exact chord progression (e.g., C-G-Am-F or I'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prompt = prompt_base.format(user_text=clean_user_text, additional_data=combined_data)\n",
    "final_prompt[1000:1100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user's text describes a state of calm but with an underlying sense of something being \"out of place,\" a feeling of being \"on pause,\" neither sad nor joyful, but introspective. This suggests a gentle, contemplative mood, not overtly emotional but with a subtle undercurrent of something unresolved.\n",
      "\n",
      "Here's a musical interpretation reflecting this emotional state:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"Tempo\": \"Andante (moderately slow)\",\n",
      "  \"Intensity/Dynamics\": \"Piano to mezzo piano, with subtle crescendos and diminuendos to emphasize introspective moments and create a sense of gentle unfolding.\",\n",
      "  \"Timbre\": \"Warm, mellow timbre. Instruments like a solo cello, acoustic guitar, or a muted trumpet would suit this mood. Avoid harsh or bright timbres.\",\n",
      "  \"Rhythm\": \"Predominantly regular, with occasional subtle rhythmic variations to add interest without disrupting the calm. Simple, even note values.\",\n",
      "  \"Harmonic progression\": \"Am - G - C - F (vi - V - I - IV)  This progression in A minor creates a gentle, melancholic atmosphere, resolving to the tonic (I) but with a touch of unresolved tension through the vi chord and the plagal cadence (IV-I).\",\n",
      "  \"Melody\": \"Mostly descending melodic lines to reflect the feeling of being ‘on pause’. The melody will have a gentle, flowing quality. Occasional slight ascents can be used to represent glimmers of hope or potential.\",\n",
      "  \"Tonality/Mode\": \"A minor (Aeolian mode). The A minor key provides the melancholic yet peaceful background that suits the described introspection. The Aeolian mode is especially appropriate because it mirrors the subtle sense of incompleteness within the emotional state.\",\n",
      "  \"Articulation\": \"Legato (smooth, connected notes) for most of the piece to emphasize the calm and introspection. Occasional slight use of staccato (short, detached notes) could punctuate introspective moments.\",\n",
      "  \"Silence\": \"Strategic use of rests within the melody and harmony, creating space for reflection. This will allow the listener to take in and digest the emotions conveyed by the music.\"\n",
      "}\n",
      "```\n",
      "\n",
      "**Justification of Choices:**\n",
      "\n",
      "* **Tempo:** Andante reflects the calm and unhurried nature of the emotional state. A fast tempo would contradict the sense of being \"on pause.\"\n",
      "\n",
      "* **Intensity/Dynamics:** The soft dynamics (piano to mezzo piano) and subtle variations maintain the gentle atmosphere while adding emotional depth.\n",
      "\n",
      "* **Timbre:** Warm, mellow timbres contribute to a sense of peace and contemplation.\n",
      "\n",
      "* **Rhythm:**  The mostly regular rhythm creates stability, reflecting the calm; subtle variations avoid monotony.\n",
      "\n",
      "* **Harmonic progression:** The chosen progression in A minor creates a melancholic, yet resolving harmony, fitting the introspective and somewhat unresolved emotional state. The plagal cadence adds a subtle feeling of quiet contemplation.\n",
      "\n",
      "* **Melody:** Descending melodies mirror the feeling of being \"on pause\" or in a state of quiet contemplation.\n",
      "\n",
      "* **Tonality/Mode:** A minor (Aeolian mode) evokes the underlying subtle melancholia but avoids a dramatic or overwhelming sadness.\n",
      "\n",
      "* **Articulation:**  Legato creates a smooth, contemplative flow; occasional staccato adds a touch of emphasis.\n",
      "\n",
      "* **Silence:**  Pauses allow the music to breathe and enhance the introspective nature of the piece.\n",
      "\n",
      "\n",
      "**Melody Example (in A minor):**\n",
      "\n",
      "A - G - F - E - D - C - A  A - G - F - E - D - C - B - A\n",
      "\n",
      "\n",
      "This is just a starting point; a full composition would involve a more complex development of these themes and features to build a more complete and varied musical narrative.  The specific choice of A minor was made due to the listener expressing an openness to soft and calm music with a touch of introspection, and A minor's inherent sadness, without being aggressively melancholic, is a perfect fit.  The harmonic progression and suggested melody then follow logically from this tonal center.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"contents\": [\n",
    "        {\n",
    "            \"parts\": [{\"text\": final_prompt}]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "load_dotenv(\"data/api_key1_google.env\")\n",
    "api_key = os.getenv(\"API_KEY\") #set de api key\n",
    "\n",
    "url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={api_key}\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "#snd the request\n",
    "response = requests.post(url, headers=headers, json=payload)\n",
    "\n",
    "#proocess the response\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    print(result['candidates'][0]['content']['parts'][0]['text'])\n",
    "else:\n",
    "    print(f\"Error {response.status_code}: {response.json()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obtenemos una respuesta bastante contundente parece ser. Nos da una base en la que probar a construir una pequeña melodía"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vamos a probar con otros textos de distintos usuarios a ver que dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_text_depressed = \"\"\"\n",
    "It's one of those days where everything feels heavy, like I'm sinking into myself. \n",
    "Even the smallest things seem pointless, and no matter what I do, it feels like there's no real way out. \n",
    "There's this emptiness that just sits there, quiet but overwhelming. \n",
    "If it were music, it would be slow and haunting, something that pulls you deeper with every note.\n",
    "\"\"\"\n",
    "clean_depressed_text = preprocess_text(user_text_depressed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt_depressed = prompt_base.format(user_text=clean_depressed_text, additional_data=combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the user's text and the provided additional data, here's an analysis of the emotional state and its translation into musical characteristics:\n",
      "\n",
      "**Musical Characteristics:**\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"Tempo\": \"Largo (40-60 bpm)\",\n",
      "  \"Intensity/Dynamics\": \"Piano to pianissimo with occasional, subtle crescendos that quickly decrescendo, mirroring the overwhelming but quiet nature of the emptiness.\",\n",
      "  \"Timbre\": \"Dark, somber. Instruments like cello, viola, or a low-register string quartet would be suitable.  Avoid bright or sharp timbres.\",\n",
      "  \"Rhythm\": \"Irregular, with rubato (flexible tempo) to emphasize the feeling of sinking and unease. Simple, repetitive rhythmic figures might underscore the feeling of being trapped.\",\n",
      "  \"Harmonic progression\": \"Am - F - C - G - Am (vi - IV - i - V - vi) -  This progression utilizes a minor tonality (A minor) which reinforces the feeling of sadness and heaviness. The movement towards the tonic (i) is delayed and ambiguous, reflecting the sense of no way out.\",\n",
      "  \"Melody\": \"Predominantly descending melodic lines, with occasional, brief upward movements that quickly fall back down.  The overall shape should be arching downward, representing the feeling of sinking.\",\n",
      "  \"Tonality/Mode\": \"A minor (Aeolian mode)\",\n",
      "  \"Articulation\": \"Legato (smooth, connected notes) for the majority of the piece, except for brief staccato notes (short, detached notes) to accentuate moments of despair or tension.\",\n",
      "  \"Silence\": \"Strategic use of rests (pauses) of varying lengths, creating a sense of emptiness and allowing the listener to fully experience the weight of the emotional state. The pauses should be incorporated within the phrases and the overall piece.\"\n",
      "}\n",
      "```\n",
      "\n",
      "**Justification:**\n",
      "\n",
      "* **Tempo:** The text explicitly states \"slow and haunting,\" indicating a slow tempo like Largo.\n",
      "* **Intensity/Dynamics:** The description of \"quiet but overwhelming\" emptiness suggests a generally low dynamic level (piano to pianissimo), with occasional, subtle increases in volume (crescendos) that are short-lived, reflecting the fleeting moments of heightened emotion within the overall sense of despair.\n",
      "* **Timbre:** Dark timbres like those produced by cellos and violas create a somber atmosphere aligned with feelings of heaviness and emptiness.\n",
      "* **Rhythm:** The irregular rhythm and use of rubato mirror the lack of stability and the feeling of being pulled deeper into a negative emotional state.\n",
      "* **Harmonic progression:** The chosen progression in A minor creates a melancholic mood. The avoidance of a clear resolution in the cadence prolongs the emotional ambiguity and the feeling of being trapped.  The progression is based on the user's implicit reference to minor key sadness, as established by the additional material. The delay of resolution emphasizes the sense of being trapped.\n",
      "* **Melody:** Descending melodies directly reflect the feeling of sinking and despair.  The occasional upward movement adds a momentary flicker of hope before returning to the overall downward trajectory.\n",
      "* **Tonality/Mode:** A minor (Aeolian mode) is chosen to represent the melancholic tone of the text, with its dark and somber nature aligned with the feelings described. The additional data about the association between minor keys and sadness is relevant here.\n",
      "* **Articulation:** Legato emphasizes the continuous and overwhelming nature of the emotional state, while staccato punctuates the moments of heightened anxiety or hopelessness.\n",
      "* **Silence:** Pauses are crucial to the overall effect of the piece, creating the sense of profound emptiness and the heavy silence that permeates the emotional state.\n",
      "\n",
      "\n",
      "**Melody Example (in A minor):**\n",
      "\n",
      "A4 - G4 - F4 - E4 - F4 - G4 - A4 - G4 - E4 - C4 - A3 - G3 - A3 (This is a basic example and can be further developed.)\n",
      "\n",
      "This melody showcases a descending line, reflects the feeling of sinking and is in the selected tonality. The short upward movement (F4-G4-A4) followed by the return to lower notes illustrates the brief glimpses of hope before sinking into the pervasive emotional state.  Remember to consider the rhythm (irregularity), dynamics (pianissimo to piano), and articulation (mostly legato) when performing this melody.  The final cadence would follow the Am - F - C - G progression, creating a sense of unresolved despair.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"contents\": [\n",
    "        {\n",
    "            \"parts\": [{\"text\": final_prompt_depressed}]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "load_dotenv(\"data/api_key1_google.env\")\n",
    "api_key = os.getenv(\"API_KEY\") #set de api key\n",
    "\n",
    "url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={api_key}\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "#snd the request\n",
    "response = requests.post(url, headers=headers, json=payload)\n",
    "\n",
    "#proocess the response\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    print(result['candidates'][0]['content']['parts'][0]['text'])\n",
    "else:\n",
    "    print(f\"Error {response.status_code}: {response.json()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Today feels bright, like the world has this gentle glow to it. Everything seems to fit, and even small things bring a kind of quiet happiness. If I could describe it as music, it would be in B-flat major, with a light and playful melody, something that lifts you up and keeps you smiling.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_text_joyful = \"\"\"\n",
    "Today feels bright, like the world has this gentle glow to it. \n",
    "Everything seems to fit, and even small things bring a kind of quiet happiness. \n",
    "If I could describe it as music, it would be in B-flat major, with a light and playful melody, something that lifts you up and keeps you smiling.\n",
    "\"\"\"\n",
    "\n",
    "clean_joy_text = preprocess_text(user_text_joyful)\n",
    "clean_joy_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user's text describes a feeling of bright, gentle joy and contentment, even in small things.  The specified tonality of B-flat major strongly supports this emotional description.  Major keys are generally associated with happiness and optimism in Western musical traditions. The description of a \"light and playful melody\" further reinforces the positive emotional state.\n",
      "\n",
      "Here's a breakdown of the musical characteristics based on the text and additional data:\n",
      "\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"Tempo\": \"Andante (moderately slow)\",\n",
      "  \"Intensity/Dynamics\": \"mf (moderately loud) with occasional pianissimo (very soft) passages for emphasis and contrast.\",\n",
      "  \"Timbre\": \"Bright, clear timbre.  Suitable instruments might include flute, glockenspiel, strings (violins, cellos), perhaps a light piano\",\n",
      "  \"Rhythm\": \"Mostly regular, but with some subtle rhythmic variation to avoid monotony.  A predominantly triple meter (e.g., 3/4) could create a sense of gentle flow and grace\",\n",
      "  \"Harmonic progression\": \"I - IV - V - I (Bbmaj - Ebmaj - Fmaj - Bbmaj)  This is a common and satisfying progression in B-flat major, providing a sense of resolution and closure. \",\n",
      "  \"Melody\": \"Primarily stepwise motion with some leaps for interest, predominantly ascending and gently arcing, reflecting a feeling of uplift and joy.  Avoids large, jarring leaps to maintain the gentle quality.\",\n",
      "  \"Tonality/Mode\": \"B-flat major (Ionian mode).  The user explicitly requests this key, and its major tonality perfectly aligns with the bright and happy emotional description.\",\n",
      "  \"Articulation\": \"Legato (smooth and connected) playing style to enhance the gentle quality, with occasional staccato (short, detached) notes for emphasis and contrast.\",\n",
      "  \"Silence\": \"Occasional brief rests to allow for a subtle breathing space and to highlight certain notes or phrases. This can enhance emotional impact and prevents the music from becoming overly sugary.\"\n",
      "}\n",
      "```\n",
      "\n",
      "**Justification:**\n",
      "\n",
      "* **Tempo:**  \"Andante\" suggests a moderate tempo, neither too rushed nor too slow, reflecting the calm yet joyful energy.  A faster tempo might feel frantic, while a slower tempo could be too melancholic.\n",
      "\n",
      "* **Intensity/Dynamics:** A moderately loud intensity (mf) provides a generally upbeat feel, but the dynamic variation (pianissimo) adds depth and allows the listener to reflect on the feeling, creating a dynamic and interesting soundscape.\n",
      "\n",
      "* **Timbre:** Bright timbres create a feeling of openness and happiness. Instruments like the flute and glockenspiel contribute to this. Using a light piano would enhance both the positive and gentle vibes.\n",
      "\n",
      "* **Rhythm:**  A regular rhythm provides stability, while subtle variations avoid predictability. Triple meter (like a waltz) further adds to the gentle, flowing character.\n",
      "\n",
      "* **Harmonic progression:** The I-IV-V-I progression is a fundamental cadence in Western music, providing a sense of resolution and complete satisfaction, matching the contentment described.\n",
      "\n",
      "* **Melody:** Ascending melodic lines generally evoke positive emotions; stepwise motion maintains the gentle quality.\n",
      "\n",
      "* **Tonality/Mode:**  The user's explicit choice of B-flat major is essential. Major keys often convey happiness, joy, and optimism.\n",
      "\n",
      "* **Articulation:** Legato emphasizes the smooth and flowing nature of the emotion, while staccato adds a touch of playful emphasis.\n",
      "\n",
      "* **Silence:**  Brief pauses emphasize particular notes, enhancing the emotional impact without disrupting the overall flow.\n",
      "\n",
      "\n",
      "\n",
      "**Melody Example (in B-flat major):**\n",
      "\n",
      "Bb4 - C5 - D5 - Eb5 - D5 - C5 - Bb4 - A4 - G4 - F4 - Eb4 - D4 - Bb4\n",
      "\n",
      "\n",
      "This melody is stepwise in a smooth motion, with a gentle upward curve at the beginning, which moves downwards to rest softly in B-flat.  It follows the principles of a bright, joyful, and calm melody in the described tonality. Remember that this is a very rudimentary example; a full composition would involve further development and variation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_prompt_joy = prompt_base.format(user_text=clean_joy_text, additional_data=combined_data)\n",
    "\n",
    "payload = {\n",
    "    \"contents\": [\n",
    "        {\n",
    "            \"parts\": [{\"text\": final_prompt_joy}]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "load_dotenv(\"data/api_key1_google.env\")\n",
    "api_key = os.getenv(\"API_KEY\") #set de api key\n",
    "\n",
    "url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={api_key}\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "#snd the request\n",
    "response = requests.post(url, headers=headers, json=payload)\n",
    "\n",
    "#proocess the response\n",
    "if response.status_code == 200: #oood traffic\n",
    "    result = response.json()\n",
    "    print(result['candidates'][0]['content']['parts'][0]['text'])\n",
    "else:\n",
    "    print(f\"Error {response.status_code}: {response.json()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ya hemos demostrado que funciona más o menos como espérabamos, con un claro margen de depuración y mejora.\n",
    "\n",
    "vamos a modificar un pequeño detalle para que tú como usuario seas quien lo pruebe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try it!!!\n",
    "\n",
    "user_text = input('Please enter your text about how you are feeling currently : ')\n",
    "\n",
    "while not user_text.strip():\n",
    "    user_text = input(\"Text cannot be empty. Please enter your text: \")\n",
    "\n",
    "final_prompt= prompt_base.format(user_text=user_text, additional_data=combined_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im feelling a little bit odd, it seems that it doesnt matter how much effort i apply to studing i will never manage to live up to the expectations people have aboutme. Im tires y just want to relax and stop thinking\n"
     ]
    }
   ],
   "source": [
    "print(user_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the user's text expressing feelings of being \"a little bit odd,\" overwhelmed by expectations, tired, and desiring relaxation, the underlying emotional state is a blend of sadness, weariness, and a longing for peace.  The additional data reinforces the association between specific musical characteristics and emotions.\n",
      "\n",
      "Here's a musical interpretation translated from the emotional state:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"Tempo\": \"Andante (moderately slow)\",\n",
      "  \"Intensity/Dynamics\": \"Piano to mezzo-piano, with occasional diminuendos to pianissimo during moments of introspection and then a gradual crescendo towards the end suggesting a hopeful resolution.\",\n",
      "  \"Timbre\": \"Dark, warm, mellow.  Instruments like cello, viola, and muted trumpet would suit the mood.\",\n",
      "  \"Rhythm\": \"Irregular, with some syncopation to reflect the feeling of unease and instability, but punctuated by moments of simple, regular beats for brief respite.\",\n",
      "  \"Harmonic progression\": \"Am - G - C - F (vi - V - I - IV) in A minor. This progression is common in sad music, creating a sense of yearning and resolution.\",\n",
      "  \"Melody\": \"Mostly descending, reflecting the sadness and weariness. However, the melody should have brief, subtle upward movements towards the end to hint at hope and relaxation.\",\n",
      "  \"Tonality/Mode\": \"A minor (Aeolian mode). A minor has a melancholic quality that effectively captures the sadness and weariness.\",\n",
      "  \"Articulation\": \"Legato for the most part, creating a flowing, continuous sound, symbolizing the continuous flow of thoughts and feelings.  Occasional staccato notes could be used to emphasize certain words or feelings, creating contrast.\",\n",
      "  \"Silence\": \"Strategic pauses and rests between phrases will provide moments of introspection and reflect the desire for quiet contemplation and peace.\"\n",
      "}\n",
      "```\n",
      "\n",
      "**Justification of Choices:**\n",
      "\n",
      "* **Tempo:** Andante reflects the user's weariness and lack of energy. A faster tempo would contradict the expressed desire for relaxation.\n",
      "\n",
      "* **Intensity/Dynamics:** The dynamic range reflects the fluctuating emotional state—moments of intense feelings contrasted with periods of calm introspection. The crescendo shows a hopeful, positive resolution.\n",
      "\n",
      "* **Timbre:** Dark and mellow timbres enhance the melancholic feeling. Bright timbres would be inappropriate given the emotional state.\n",
      "\n",
      "* **Rhythm:** Irregularity reflects the unease and instability; regular beats provide contrast and relief.\n",
      "\n",
      "* **Harmonic progression:** The Am - G - C - F progression in A minor is a classic progression used to express sadness and longing.  It provides a sense of closure.\n",
      "\n",
      "* **Melody:** Descending melodies are often associated with sadness.  The subtle upward turn at the end represents a glimmer of hope.\n",
      "\n",
      "* **Tonality/Mode:** A minor's inherent sadness aligns with the user's emotional state.\n",
      "\n",
      "* **Articulation:** Legato creates a seamless flow reflecting the continuous nature of the feelings; staccato adds emphasis.\n",
      "\n",
      "* **Silence:** Silences allow the listener to process emotions and reflect on the desire for peace and calm.\n",
      "\n",
      "\n",
      "**Melody Example (in A minor):**\n",
      "\n",
      "A - G - F - E  -  A - G - F - E  - D - C - E - A\n",
      "\n",
      "This is a very basic example. A full composition would involve much more melodic detail and variation in rhythm and dynamics to capture the nuances of the emotions expressed.  The progression would also be repeated and developed to create a longer piece.  This melody aims to illustrate the general descending shape and the brief upward inflection before the final note.  The final A is intended to be slightly louder and longer than the preceding notes, symbolizing a move towards resolution and peace, even though it remains within the melancholic A minor key.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"contents\": [\n",
    "        {\n",
    "            \"parts\": [{\"text\": final_prompt}]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "load_dotenv(\"data/api_key1_google.env\") #this is our api_key (must be private and unshared), get yours in https://aistudio.google.com/app/apikey\n",
    "api_key = os.getenv(\"API_KEY\") #set de api key\n",
    "\n",
    "url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={api_key}\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "#snd the request\n",
    "response = requests.post(url, headers=headers, json=payload)\n",
    "\n",
    "#proocess the response\n",
    "if response.status_code == 200: #oood traffic\n",
    "    result = response.json()\n",
    "    print(result['candidates'][0]['content']['parts'][0]['text'])\n",
    "else:\n",
    "    print(f\"Error {response.status_code}: {response.json()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
